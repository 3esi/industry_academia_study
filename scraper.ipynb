{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of the sessions and the corresponding papers/talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of dynamic content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sessions_papers(url):\n",
    "    \"\"\"\n",
    "    Extracts session and paper details from a given conference URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the conference page from which to extract data.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are session names and the values are dictionaries containing paper details.\n",
    "              Each paper detail dictionary contains:\n",
    "              - 'name': The title of the paper (str)\n",
    "              - 'authors': A list of authors' names (list of str)\n",
    "              - 'url': The URL to the paper (str)\n",
    "    \"\"\"\n",
    "    # Set up Chrome options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "\n",
    "    # Set up the Chrome WebDriver using ChromeDriverManager\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    # Open the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to fully load (adjust time as needed)\n",
    "    time.sleep(5)  # Increased wait time to ensure the page is fully loaded\n",
    "\n",
    "    # Get the page source after JavaScript has rendered\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # Parse the page content with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Find all divs with the classes 'hidable' and 'band'\n",
    "    all_divs = soup.find_all(\"div\", class_=[\"hidable\", \"band\"])\n",
    "\n",
    "    # Filter for only visible divs\n",
    "    visible_divs = [div for div in all_divs if div.get(\"data-is-visible\") == \"true\"]\n",
    "\n",
    "    # Initialize the dictionary to store sessions with additional details\n",
    "    sessions_details = {}\n",
    "\n",
    "    # Iterate over each visible div\n",
    "    for visible_div in visible_divs:\n",
    "        # Find the session table inside the div\n",
    "        session_table = visible_div.find(\"table\", class_=\"session-table\")\n",
    "        \n",
    "        if session_table:\n",
    "            # Find the tbody element\n",
    "            tbody = session_table.find(\"tbody\")\n",
    "            \n",
    "            if tbody:\n",
    "                # Find the session name\n",
    "                session_info_elem = tbody.find(class_=\"session-info-in-table\")\n",
    "                if session_info_elem:\n",
    "                    # Extract only the first part of the text before the <span> tag\n",
    "                    session_name_parts = session_info_elem.contents\n",
    "                    session_name = \"\"\n",
    "                    \n",
    "                    for part in session_name_parts:\n",
    "                        if isinstance(part, str):  # Check if part is a string (text node)\n",
    "                            session_name += part.strip()  # Append the text part\n",
    "                            break  # Stop after the first text node\n",
    "\n",
    "                session_name = session_name if session_name else \"Unknown Session\"\n",
    "                \n",
    "                # Find all rows (tr elements) within the tbody\n",
    "                rows = tbody.find_all(\"tr\")\n",
    "                \n",
    "                # Papers start from the third row, so we skip the first two\n",
    "                paper_rows = rows[2:]\n",
    "                \n",
    "                # Extract the papers from the remaining rows, checking for visibility\n",
    "                papers = []\n",
    "                for row in paper_rows:\n",
    "                    if row.get(\"data-is-visible\") == \"true\" and row.get(\"style\") != \"display: none;\":\n",
    "                        # Extract the paper name from the 4th td element\n",
    "                        td_elements = row.find_all(\"td\")\n",
    "                        if len(td_elements) >= 4:\n",
    "                            paper_name_elem = td_elements[3].find(\"strong\")\n",
    "                            paper_name = paper_name_elem.get_text(strip=True) if paper_name_elem else \"Unknown Paper\"\n",
    "                        \n",
    "                            # Extract authors\n",
    "                            authors_div = td_elements[3].find(\"div\", class_=\"performers\")\n",
    "                            authors = [a.get_text(strip=True) for a in authors_div.find_all(\"a\")] if authors_div else []\n",
    "\n",
    "                            # Extract paper URL\n",
    "                            url_elem = td_elements[3].find(\"a\", class_=\"publication-link\")\n",
    "                            paper_url = url_elem['href'] if url_elem else \"No URL available\"\n",
    "                            \n",
    "                            papers.append({\n",
    "                                \"name\": paper_name,\n",
    "                                \"authors\": authors,\n",
    "                                \"url\": paper_url\n",
    "                            })\n",
    "                \n",
    "                # Store the session details in the dictionary\n",
    "                if papers:\n",
    "                    sessions_details[session_name] = {\n",
    "                        \"papers\": papers\n",
    "                    }\n",
    "    \n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    return sessions_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sessions_and_papers(conference_dict):\n",
    "    \"\"\"\n",
    "    Prints details of sessions and their associated papers.\n",
    "\n",
    "    Parameters:\n",
    "    conference_dict (dict): A dictionary where keys are session names and values are dictionaries with papers.\n",
    "    \"\"\"\n",
    "    for session_name, details in conference_dict.items():\n",
    "        print(f\"Session: {session_name}\")\n",
    "        for paper in details['papers']:\n",
    "            print(f\" - Paper: {paper['name']}\")\n",
    "            print(f\"   Authors: {', '.join(paper['authors'])}\")\n",
    "            print(f\"   URL: {paper['url']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_session_names(conference_dict):\n",
    "    \"\"\"\n",
    "    Prints the names of sessions from a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    conference_dict (dict): A dictionary where keys are session names.\n",
    "    \"\"\"\n",
    "    for session_name in conference_dict.keys():\n",
    "        print(f\"{session_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roman_to_int(roman):\n",
    "    \"\"\"\n",
    "    Converts a Roman numeral to an integer. This function only converts Roman numerals \n",
    "    that are standalone, preceded and followed by spaces or are at the start/end of the string.\n",
    "\n",
    "    Parameters:\n",
    "    roman (str): A Roman numeral as a string.\n",
    "\n",
    "    Returns:\n",
    "    int: The integer representation of the Roman numeral, or None if the input is not a valid standalone Roman numeral.\n",
    "    \"\"\"\n",
    "    roman_numerals = {\n",
    "        'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, \n",
    "        'D': 500, 'M': 1000\n",
    "    }\n",
    "    \n",
    "    # Regex pattern to match a valid Roman numeral surrounded by spaces or at the boundaries\n",
    "    pattern = re.compile(r'(^|\\s)(I{1,3}|IV|VI{0,3}|IX|X{1,3}|XL|L?X{0,3}|XC|C{1,3}|CD|D?C{0,3}|CM|M{0,3})(\\s|$)')\n",
    "    \n",
    "    # Find if the input matches the Roman numeral pattern\n",
    "    match = pattern.match(roman)\n",
    "    \n",
    "    if not match:\n",
    "        return None\n",
    "    \n",
    "    roman = match.group(2)  # Extract the Roman numeral part from the match\n",
    "\n",
    "    # Convert Roman numeral to integer\n",
    "    total = 0\n",
    "    prev_value = 0\n",
    "    for char in reversed(roman):\n",
    "        value = roman_numerals.get(char, 0)\n",
    "        if value < prev_value:\n",
    "            total -= value\n",
    "        else:\n",
    "            total += value\n",
    "        prev_value = value\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sessions_by_name(conference_dict):\n",
    "    \"\"\"\n",
    "    Merges sessions with the same base topic into a single session, e.g. \"Testing 1\" and \"Testing II\".\n",
    "\n",
    "    This function consolidates multiple sessions that share the same base topic but differ in their numbering \n",
    "    (either Arabic or Roman numerals) into a single session. It uses regular expressions to identify sessions \n",
    "    with similar base names, combines their associated papers, and returns a dictionary where each key \n",
    "    represents a unique base session name with all its associated papers aggregated.\n",
    "\n",
    "    Parameters:\n",
    "    conference_dict (dict): A dictionary where:\n",
    "        - The keys are session names (strings), which may include a base topic and an optional number suffix (e.g., \"Testing 1\", \"Testing II\").\n",
    "        - The values are dictionaries with a key 'papers', which maps to a list of dictionaries. Each dictionary in the 'papers' list contains:\n",
    "            - 'name' (str): The title of the paper.\n",
    "            - 'authors' (list of str): A list of authors of the paper.\n",
    "            - 'url' (str): The URL to access the paper.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where:\n",
    "        - The keys are base session names (strings) derived from the input session names.\n",
    "        - The values are dictionaries with a key 'papers' that contains a list of all papers associated with that base session name.\n",
    "\n",
    "    \"\"\"\n",
    "    # Dictionary to group papers by session base name\n",
    "    merged_sessions = defaultdict(lambda: {'papers': []})\n",
    "    \n",
    "    # Regular expression to extract base name and number (either Arabic or Roman numerals)\n",
    "    pattern = re.compile(r'^(.*?)(?:\\s+(\\d+|[IVXLCDM]+))?$')\n",
    "    \n",
    "    for session_name, details in conference_dict.items():\n",
    "        # Extract the base name and number using regex\n",
    "        match = pattern.match(session_name)\n",
    "        if match:\n",
    "            base_name = match.group(1).strip()\n",
    "            num_suffix = match.group(2).strip() if match.group(2) else ''\n",
    "            \n",
    "            # Convert Roman numerals to integers for consistency, if applicable\n",
    "            if re.match(r'^[IVXLCDM]+$', num_suffix):\n",
    "                num_suffix = roman_to_int(num_suffix)\n",
    "            else:\n",
    "                num_suffix = int(num_suffix) if num_suffix.isdigit() else None\n",
    "            \n",
    "            # Append papers to the corresponding base name in the merged_sessions\n",
    "            merged_sessions[base_name]['papers'].extend(details['papers'])\n",
    "    \n",
    "    # Convert defaultdict to a regular dict\n",
    "    return dict(merged_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix_of_sessions(conference_dict):\n",
    "    \"\"\"\n",
    "    Cleans the session names in the dictionary by removing the prefix 'Technical Session' along with its number and \n",
    "    the dash ('-'). Only the part after the dash ('-') is kept as the session name.\n",
    "\n",
    "    Parameters:\n",
    "    conference_dict (dict): A dictionary where:\n",
    "        - The keys are session names (strings), which may include 'Technical Session', a number, and a dash ('-') prefix.\n",
    "        - The values are dictionaries with a key 'papers', which maps to a list of dictionaries. Each dictionary in the 'papers' list contains:\n",
    "            - 'name' (str): The title of the paper.\n",
    "            - 'authors' (list of str): A list of authors of the paper.\n",
    "            - 'url' (str): The URL to access the paper.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where:\n",
    "        - The keys are cleaned session names (strings), derived from the input session names.\n",
    "        - The values are dictionaries with a key 'papers' that contains a list of all papers associated with that cleaned session name.\n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_sessions = {}\n",
    "    \n",
    "    # Regular expression to match 'Technical Session' followed by a number and a dash\n",
    "    pattern = re.compile(r'^Technical Session \\d+ - (.+)$')\n",
    "\n",
    "    for session_name, details in conference_dict.items():\n",
    "        # Check if session name matches the pattern\n",
    "        match = pattern.match(session_name)\n",
    "        if match:\n",
    "            # Extract and clean the session name\n",
    "            cleaned_name = match.group(1).strip()\n",
    "        else:\n",
    "            # Keep the original name if it does not match the pattern\n",
    "            cleaned_name = session_name\n",
    "        \n",
    "        # Add the papers to the cleaned session name\n",
    "        if cleaned_name in cleaned_sessions:\n",
    "            cleaned_sessions[cleaned_name]['papers'].extend(details['papers'])\n",
    "        else:\n",
    "            cleaned_sessions[cleaned_name] = details\n",
    "    \n",
    "    return cleaned_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sessions(dicts):\n",
    "    \"\"\"\n",
    "    Merge multiple dictionaries containing session and paper details based on exact session names.\n",
    "    \n",
    "    Args:\n",
    "        dicts (list of dict): List of dictionaries where each dictionary contains sessions and their papers.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A merged dictionary with session names as keys and combined paper details as values.\n",
    "    \"\"\"\n",
    "    # Dictionary to hold the merged results\n",
    "    merged_sessions = defaultdict(lambda: {\"papers\": []})\n",
    "    \n",
    "    for session_dict in dicts:\n",
    "        for session_name, details in session_dict.items():\n",
    "            # Add the papers to the merged_sessions dictionary under the exact session name\n",
    "            merged_sessions[session_name][\"papers\"].extend(details[\"papers\"])\n",
    "    \n",
    "    # Convert defaultdict to a regular dict\n",
    "    return dict(merged_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASE 2022-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASE 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ASE 2023 36 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ase2023_url = \"https://conf.researchr.org/track/ase-2023/ase-2023-papers?track=ASE%20Research%20Papers#program\"\n",
    "ase2023 = extract_sessions_papers(ase2023_url)\n",
    "\n",
    "print(\"Sessions in ASE 2023\", len(ase2023), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_sessions_and_papers(ase2023)\n",
    "#print_session_names(ase2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ASE 2023 after cleaning 22 \n",
      "\n",
      "Cloud and Distributed Systems\n",
      "Testing AI Systems\n",
      "Infrastructure, Build, and Logs\n",
      "Open Source and Software Ecosystems\n",
      "Smart Contracts, Blockchain, Energy efficiency, and green software\n",
      "Vulnerability and Security\n",
      "Code Generation\n",
      "Web Development\n",
      "Testing Tools and Techniques\n",
      "Code Quality and Code Smells\n",
      "Program Repair\n",
      "Program Analysis\n",
      "Code Summarization\n",
      "Program Verification\n",
      "Code Change Analysis\n",
      "Software Testing for Specialized Systems\n",
      "Bug Detection\n",
      "Autonomous Systems and Agents\n",
      "Mobile Development\n",
      "Debugging\n",
      "Fuzzing\n",
      "Configuration and Version Management\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "ase2023_cleaned = merge_sessions_by_name(ase2023)\n",
    "\n",
    "print(\"Sessions in ASE 2023 after cleaning\", len(ase2023_cleaned), \"\\n\")\n",
    "\n",
    "print_session_names(ase2023_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASE 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ASE 2022 35 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ase2022_url = \"https://conf.researchr.org/program/ase-2022/program-ase-2022/?track=ASE%20Research%20Papers\"\n",
    "ase2022 = extract_sessions_papers(ase2022_url)\n",
    "\n",
    "print(\"Sessions in ASE 2022\", len(ase2022), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ase2022_noprefix = remove_prefix_of_sessions(ase2022)\n",
    "#print_session_names(ase2022_noprefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ASE 2022 after cleaning 26 \n",
      "\n",
      "Welcome to Day\n",
      "AI for SE\n",
      "Debugging and Troubleshooting\n",
      "Fuzzing\n",
      "Mobile Apps\n",
      "Code Analysis\n",
      "Source Code Manipulation\n",
      "Security and Privacy\n",
      "Testing\n",
      "Builds and Versions\n",
      "Analysis and Types\n",
      "Application Domains\n",
      "Bug Prediction and Localization\n",
      "Compilers and Languages\n",
      "Software Vulnerabilities\n",
      "Formal Methods and Models\n",
      "SE for AI\n",
      "Web, Cloud, Networking\n",
      "Security\n",
      "Code Summarization and Recommendation\n",
      "Human Aspects\n",
      "Software Repairs\n",
      "Dynamic and Concolic Analysis\n",
      "Safety-Critical and Self-Adaptive Systems\n",
      "Code Similarities and Refactoring\n",
      "Builds and Dependencies\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "ase2022_cleaned = merge_sessions_by_name(ase2022_noprefix)\n",
    "\n",
    "print(\"Sessions in ASE 2022 after cleaning\", len(ase2022_cleaned), \"\\n\")\n",
    "\n",
    "print_session_names(ase2022_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge both ASE dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in both ASE dictionaries 47 \n",
      "\n",
      "Welcome to Day\n",
      "AI for SE\n",
      "Debugging and Troubleshooting\n",
      "Fuzzing\n",
      "Mobile Apps\n",
      "Code Analysis\n",
      "Source Code Manipulation\n",
      "Security and Privacy\n",
      "Testing\n",
      "Builds and Versions\n",
      "Analysis and Types\n",
      "Application Domains\n",
      "Bug Prediction and Localization\n",
      "Compilers and Languages\n",
      "Software Vulnerabilities\n",
      "Formal Methods and Models\n",
      "SE for AI\n",
      "Web, Cloud, Networking\n",
      "Security\n",
      "Code Summarization and Recommendation\n",
      "Human Aspects\n",
      "Software Repairs\n",
      "Dynamic and Concolic Analysis\n",
      "Safety-Critical and Self-Adaptive Systems\n",
      "Code Similarities and Refactoring\n",
      "Builds and Dependencies\n",
      "Cloud and Distributed Systems\n",
      "Testing AI Systems\n",
      "Infrastructure, Build, and Logs\n",
      "Open Source and Software Ecosystems\n",
      "Smart Contracts, Blockchain, Energy efficiency, and green software\n",
      "Vulnerability and Security\n",
      "Code Generation\n",
      "Web Development\n",
      "Testing Tools and Techniques\n",
      "Code Quality and Code Smells\n",
      "Program Repair\n",
      "Program Analysis\n",
      "Code Summarization\n",
      "Program Verification\n",
      "Code Change Analysis\n",
      "Software Testing for Specialized Systems\n",
      "Bug Detection\n",
      "Autonomous Systems and Agents\n",
      "Mobile Development\n",
      "Debugging\n",
      "Configuration and Version Management\n"
     ]
    }
   ],
   "source": [
    "# Merging the dictionaries\n",
    "merged_dict_ase = merge_sessions([ase2022_cleaned, ase2023_cleaned])\n",
    "\n",
    "print(\"Sessions in both ASE dictionaries\", len(merged_dict_ase), \"\\n\")\n",
    "\n",
    "#print_sessions_and_papers(merged_dict)\n",
    "print_session_names(merged_dict_ase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSE 2023-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSE 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in FSE 2024 32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fse2024_url = \"https://2024.esec-fse.org/program/program-fse-2024/?track=FSE%20Research%20Papers\"\n",
    "fse2024 = extract_sessions_papers(fse2024_url)\n",
    "\n",
    "print(\"Sessions in FSE 2024\", len(fse2024), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_sessions_and_papers(fse2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in FSE 2024 after cleaning 15 \n",
      "\n",
      "Software Maintenance and Comprehension\n",
      "Human Aspects\n",
      "Formal Verification\n",
      "Code Search and Completion\n",
      "Processes, Requirements, and Architecture\n",
      "Empirical Studies\n",
      "Testing\n",
      "AI4SE\n",
      "Program Analysis and Performance\n",
      "Program Repair and Synthesis\n",
      "Fault Diagnosis and Root Cause Analysis\n",
      "SE4AI\n",
      "Security and Privacy\n",
      "Log Analysis and Debugging\n",
      "Fuzzing\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "fse2024_cleaned = merge_sessions_by_name(fse2024)\n",
    "\n",
    "print(\"Sessions in FSE 2024 after cleaning\", len(fse2024_cleaned), \"\\n\")\n",
    "\n",
    "print_session_names(fse2024_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSE 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in FSE 2023 32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fse2023_url = \"https://2023.esec-fse.org/program/program-fse-2023/?track=ESEC%2FFSE%20Research%20Papers\"\n",
    "\n",
    "fse2023 = extract_sessions_papers(fse2023_url)\n",
    "\n",
    "print(\"Sessions in FSE 2023\", len(fse2023), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_sessions_and_papers(fse2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in FSE 2023 after cleaning 16 \n",
      "\n",
      "Human Aspects\n",
      "Testing\n",
      "Machine Learning\n",
      "Automated Repair\n",
      "Empirical Studies\n",
      "Software Evolution\n",
      "Program Analysis\n",
      "Code Search and Text to Code\n",
      "Log Analysis and Debugging\n",
      "Fault Diagnosis and Root Cause Analysis\n",
      "Clone and Similarity Detection\n",
      "Performance\n",
      "Security\n",
      "Fuzzing\n",
      "Formal Verification\n",
      "Models of Code and Documentation\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "fse2023_cleaned = merge_sessions_by_name(fse2023)\n",
    "\n",
    "print(\"Sessions in FSE 2023 after cleaning\", len(fse2023_cleaned), \"\\n\")\n",
    "\n",
    "print_session_names(fse2023_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge both FSE dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in both FSE dictionaries 24 \n",
      "\n",
      "Human Aspects\n",
      "Testing\n",
      "Machine Learning\n",
      "Automated Repair\n",
      "Empirical Studies\n",
      "Software Evolution\n",
      "Program Analysis\n",
      "Code Search and Text to Code\n",
      "Log Analysis and Debugging\n",
      "Fault Diagnosis and Root Cause Analysis\n",
      "Clone and Similarity Detection\n",
      "Performance\n",
      "Security\n",
      "Fuzzing\n",
      "Formal Verification\n",
      "Models of Code and Documentation\n",
      "Software Maintenance and Comprehension\n",
      "Code Search and Completion\n",
      "Processes, Requirements, and Architecture\n",
      "AI4SE\n",
      "Program Analysis and Performance\n",
      "Program Repair and Synthesis\n",
      "SE4AI\n",
      "Security and Privacy\n"
     ]
    }
   ],
   "source": [
    "# Merging the dictionaries\n",
    "merged_dict_fse = merge_sessions([fse2023_cleaned, fse2024_cleaned])\n",
    "\n",
    "print(\"Sessions in both FSE dictionaries\", len(merged_dict_fse), \"\\n\")\n",
    "\n",
    "#print_sessions_and_papers(merged_dict)\n",
    "print_session_names(merged_dict_fse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICSE 2023-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICSE 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ICSE 2024:  71 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "icse2024_url = \"https://conf.researchr.org/program/icse-2024/program-icse-2024/?track=ICSE%20Research%20Track\"\n",
    "icse2024 = extract_sessions_papers(icse2024_url)\n",
    "\n",
    "print(\"Sessions in ICSE 2024: \", len(icse2024), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ICSE 2024 after cleaning 24 \n",
      "\n",
      "AI & Security\n",
      "Evolution & AI\n",
      "Testing\n",
      "Analysis\n",
      "Human and Social\n",
      "Generative AI studies\n",
      "Language Models and Generated Code\n",
      "Program Repair\n",
      "Analytics\n",
      "Security\n",
      "Evolution\n",
      "Analysis and Debugging\n",
      "LLM, NN and other AI technologies\n",
      "Dependability and Formal methods\n",
      "Analytics & AI\n",
      "Program binaries - evolvability\n",
      "Testing: various bug types\n",
      "Human and Social Aspects, and Requirements\n",
      "Fuzzing\n",
      "Requirements\n",
      "Testing with and for AI\n",
      "Vulnerability Detection\n",
      "Static Detection Techniques\n",
      "Testing of AI systems\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "icse2024_cleaned = merge_sessions_by_name(icse2024)\n",
    "\n",
    "print(\"Sessions in ICSE 2024 after cleaning\", len(icse2024_cleaned), \"\\n\")\n",
    "\n",
    "print_session_names(icse2024_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICSE 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ICSE 2023 63 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "icse2023_url = \"https://conf.researchr.org/program/icse-2023/program-icse-2023/?track=ICSE%20Technical%20Track\"\n",
    "icse2023 = extract_sessions_papers(icse2023_url)\n",
    "\n",
    "print(\"Sessions in ICSE 2023\", len(icse2023), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ICSE 2023 after cleaning 60 \n",
      "\n",
      "AI models for SE\n",
      "Fuzzing: applications\n",
      "Mining software repositories\n",
      "Fault localization\n",
      "Formal verification\n",
      "APIs and libraries\n",
      "Blockchain/smart contracts\n",
      "Cognitive aspects of software development\n",
      "Code smells and clones\n",
      "Fuzzing: techniques and tools\n",
      "Software architectures and design\n",
      "Software security and privacy\n",
      "AI systems engineering\n",
      "Debugging\n",
      "Defect analysis\n",
      "Developers' behaviors\n",
      "Program translation and synthesis\n",
      "Posters\n",
      "Documentation\n",
      "Software logging\n",
      "Test generation\n",
      "SE for security\n",
      "Development and evolution of AI-intensive systems\n",
      "Vulnerability analysis and assessment\n",
      "Defect detection and prediction\n",
      "Studies on gender in SE\n",
      "AI testing\n",
      "Code review\n",
      "Program repair techniques and applications\n",
      "Requirements elicitation and understanding\n",
      "Software verification\n",
      "Testing of mobile, web and games\n",
      "Recommender systems\n",
      "Program repair with and for AI\n",
      "Programming languages\n",
      "AI bias and fairness\n",
      "Requirements engineering\n",
      "Software Evolution\n",
      "Test quality and improvement\n",
      "Runtime analysis and self-adaptation\n",
      "Developers' forums\n",
      "Program comprehension\n",
      "Reverse engineering\n",
      "Software processes\n",
      "Static analysis\n",
      "Testing of database and low-level software\n",
      "Software performance\n",
      "Code generation\n",
      "Software development tools\n",
      "Fault injection and mutation\n",
      "Vulnerability detection\n",
      "Issue reporting and reproduction\n",
      "Software quality\n",
      "SE education methods and tools\n",
      "Metamorphic testing\n",
      "Pre-trained and few shot learning for SE\n",
      "Program analysis\n",
      "Vulnerability testing and patching\n",
      "Cyber-physical systems testing\n",
      "Software ecosystems\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "icse2023_cleaned = merge_sessions_by_name(icse2023)\n",
    "\n",
    "print(\"Sessions in ICSE 2023 after cleaning\", len(icse2023_cleaned), \"\\n\")\n",
    "\n",
    "print_session_names(icse2023_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge both ICSE dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in both ICSE dictionaries 84 \n",
      "\n",
      "AI models for SE\n",
      "Fuzzing: applications\n",
      "Mining software repositories\n",
      "Fault localization\n",
      "Formal verification\n",
      "APIs and libraries\n",
      "Blockchain/smart contracts\n",
      "Cognitive aspects of software development\n",
      "Code smells and clones\n",
      "Fuzzing: techniques and tools\n",
      "Software architectures and design\n",
      "Software security and privacy\n",
      "AI systems engineering\n",
      "Debugging\n",
      "Defect analysis\n",
      "Developers' behaviors\n",
      "Program translation and synthesis\n",
      "Posters\n",
      "Documentation\n",
      "Software logging\n",
      "Test generation\n",
      "SE for security\n",
      "Development and evolution of AI-intensive systems\n",
      "Vulnerability analysis and assessment\n",
      "Defect detection and prediction\n",
      "Studies on gender in SE\n",
      "AI testing\n",
      "Code review\n",
      "Program repair techniques and applications\n",
      "Requirements elicitation and understanding\n",
      "Software verification\n",
      "Testing of mobile, web and games\n",
      "Recommender systems\n",
      "Program repair with and for AI\n",
      "Programming languages\n",
      "AI bias and fairness\n",
      "Requirements engineering\n",
      "Software Evolution\n",
      "Test quality and improvement\n",
      "Runtime analysis and self-adaptation\n",
      "Developers' forums\n",
      "Program comprehension\n",
      "Reverse engineering\n",
      "Software processes\n",
      "Static analysis\n",
      "Testing of database and low-level software\n",
      "Software performance\n",
      "Code generation\n",
      "Software development tools\n",
      "Fault injection and mutation\n",
      "Vulnerability detection\n",
      "Issue reporting and reproduction\n",
      "Software quality\n",
      "SE education methods and tools\n",
      "Metamorphic testing\n",
      "Pre-trained and few shot learning for SE\n",
      "Program analysis\n",
      "Vulnerability testing and patching\n",
      "Cyber-physical systems testing\n",
      "Software ecosystems\n",
      "AI & Security\n",
      "Evolution & AI\n",
      "Testing\n",
      "Analysis\n",
      "Human and Social\n",
      "Generative AI studies\n",
      "Language Models and Generated Code\n",
      "Program Repair\n",
      "Analytics\n",
      "Security\n",
      "Evolution\n",
      "Analysis and Debugging\n",
      "LLM, NN and other AI technologies\n",
      "Dependability and Formal methods\n",
      "Analytics & AI\n",
      "Program binaries - evolvability\n",
      "Testing: various bug types\n",
      "Human and Social Aspects, and Requirements\n",
      "Fuzzing\n",
      "Requirements\n",
      "Testing with and for AI\n",
      "Vulnerability Detection\n",
      "Static Detection Techniques\n",
      "Testing of AI systems\n"
     ]
    }
   ],
   "source": [
    "# Merging the dictionaries\n",
    "merged_dict_icse = merge_sessions([icse2023_cleaned, icse2024_cleaned])\n",
    "\n",
    "print(\"Sessions in both ICSE dictionaries\", len(merged_dict_icse), \"\\n\")\n",
    "\n",
    "#print_sessions_and_papers(merged_dict)\n",
    "print_session_names(merged_dict_icse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in both all dictionaries 143 \n",
      "\n",
      "AI models for SE\n",
      "Fuzzing: applications\n",
      "Mining software repositories\n",
      "Fault localization\n",
      "Formal verification\n",
      "APIs and libraries\n",
      "Blockchain/smart contracts\n",
      "Cognitive aspects of software development\n",
      "Code smells and clones\n",
      "Fuzzing: techniques and tools\n",
      "Software architectures and design\n",
      "Software security and privacy\n",
      "AI systems engineering\n",
      "Debugging\n",
      "Defect analysis\n",
      "Developers' behaviors\n",
      "Program translation and synthesis\n",
      "Posters\n",
      "Documentation\n",
      "Software logging\n",
      "Test generation\n",
      "SE for security\n",
      "Development and evolution of AI-intensive systems\n",
      "Vulnerability analysis and assessment\n",
      "Defect detection and prediction\n",
      "Studies on gender in SE\n",
      "AI testing\n",
      "Code review\n",
      "Program repair techniques and applications\n",
      "Requirements elicitation and understanding\n",
      "Software verification\n",
      "Testing of mobile, web and games\n",
      "Recommender systems\n",
      "Program repair with and for AI\n",
      "Programming languages\n",
      "AI bias and fairness\n",
      "Requirements engineering\n",
      "Software Evolution\n",
      "Test quality and improvement\n",
      "Runtime analysis and self-adaptation\n",
      "Developers' forums\n",
      "Program comprehension\n",
      "Reverse engineering\n",
      "Software processes\n",
      "Static analysis\n",
      "Testing of database and low-level software\n",
      "Software performance\n",
      "Code generation\n",
      "Software development tools\n",
      "Fault injection and mutation\n",
      "Vulnerability detection\n",
      "Issue reporting and reproduction\n",
      "Software quality\n",
      "SE education methods and tools\n",
      "Metamorphic testing\n",
      "Pre-trained and few shot learning for SE\n",
      "Program analysis\n",
      "Vulnerability testing and patching\n",
      "Cyber-physical systems testing\n",
      "Software ecosystems\n",
      "AI & Security\n",
      "Evolution & AI\n",
      "Testing\n",
      "Analysis\n",
      "Human and Social\n",
      "Generative AI studies\n",
      "Language Models and Generated Code\n",
      "Program Repair\n",
      "Analytics\n",
      "Security\n",
      "Evolution\n",
      "Analysis and Debugging\n",
      "LLM, NN and other AI technologies\n",
      "Dependability and Formal methods\n",
      "Analytics & AI\n",
      "Program binaries - evolvability\n",
      "Testing: various bug types\n",
      "Human and Social Aspects, and Requirements\n",
      "Fuzzing\n",
      "Requirements\n",
      "Testing with and for AI\n",
      "Vulnerability Detection\n",
      "Static Detection Techniques\n",
      "Testing of AI systems\n",
      "Human Aspects\n",
      "Machine Learning\n",
      "Automated Repair\n",
      "Empirical Studies\n",
      "Program Analysis\n",
      "Code Search and Text to Code\n",
      "Log Analysis and Debugging\n",
      "Fault Diagnosis and Root Cause Analysis\n",
      "Clone and Similarity Detection\n",
      "Performance\n",
      "Formal Verification\n",
      "Models of Code and Documentation\n",
      "Software Maintenance and Comprehension\n",
      "Code Search and Completion\n",
      "Processes, Requirements, and Architecture\n",
      "AI4SE\n",
      "Program Analysis and Performance\n",
      "Program Repair and Synthesis\n",
      "SE4AI\n",
      "Security and Privacy\n",
      "Welcome to Day\n",
      "AI for SE\n",
      "Debugging and Troubleshooting\n",
      "Mobile Apps\n",
      "Code Analysis\n",
      "Source Code Manipulation\n",
      "Builds and Versions\n",
      "Analysis and Types\n",
      "Application Domains\n",
      "Bug Prediction and Localization\n",
      "Compilers and Languages\n",
      "Software Vulnerabilities\n",
      "Formal Methods and Models\n",
      "SE for AI\n",
      "Web, Cloud, Networking\n",
      "Code Summarization and Recommendation\n",
      "Software Repairs\n",
      "Dynamic and Concolic Analysis\n",
      "Safety-Critical and Self-Adaptive Systems\n",
      "Code Similarities and Refactoring\n",
      "Builds and Dependencies\n",
      "Cloud and Distributed Systems\n",
      "Testing AI Systems\n",
      "Infrastructure, Build, and Logs\n",
      "Open Source and Software Ecosystems\n",
      "Smart Contracts, Blockchain, Energy efficiency, and green software\n",
      "Vulnerability and Security\n",
      "Code Generation\n",
      "Web Development\n",
      "Testing Tools and Techniques\n",
      "Code Quality and Code Smells\n",
      "Code Summarization\n",
      "Program Verification\n",
      "Code Change Analysis\n",
      "Software Testing for Specialized Systems\n",
      "Bug Detection\n",
      "Autonomous Systems and Agents\n",
      "Mobile Development\n",
      "Configuration and Version Management\n"
     ]
    }
   ],
   "source": [
    "# Merging all the dictionaries\n",
    "merged_dict_all = merge_sessions([merged_dict_icse, merged_dict_fse, merged_dict_ase])\n",
    "\n",
    "print(\"Sessions in both all dictionaries\", len(merged_dict_all), \"\\n\")\n",
    "\n",
    "#print_sessions_and_papers(merged_dict)\n",
    "print_session_names(merged_dict_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping the sessions by textual similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_sessions_by_semantics(session_names, n_clusters=10):\n",
    "    \"\"\"\n",
    "    Groups session names based on their semantic similarity.\n",
    "\n",
    "    Parameters:\n",
    "    session_names (list of str): A list of session names.\n",
    "    n_clusters (int): The number of clusters to form (default is 10).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are group IDs and values are lists of session names in each group.\n",
    "    \"\"\"\n",
    "    # Convert session names to TF-IDF matrix\n",
    "    vectorizer = TfidfVectorizer().fit_transform(session_names)\n",
    "    tfidf_matrix = vectorizer.toarray()\n",
    "\n",
    "    # Perform clustering using KMeans\n",
    "    clustering = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = clustering.fit_predict(tfidf_matrix)\n",
    "\n",
    "    # Group session names by their cluster labels\n",
    "    grouped_sessions = {}\n",
    "    for label, session_name in zip(labels, session_names):\n",
    "        if label not in grouped_sessions:\n",
    "            grouped_sessions[label] = []\n",
    "        grouped_sessions[label].append(session_name)\n",
    "\n",
    "    return grouped_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_names = [\n",
    "    \"AI models for SE\",\n",
    "    \"Fuzzing: applications\",\n",
    "    \"Mining software repositories\",\n",
    "    \"Fault localization\",\n",
    "    \"Formal verification\",\n",
    "    \"APIs and libraries\",\n",
    "    \"Blockchain/smart contracts\",\n",
    "    \"Cognitive aspects of software development\",\n",
    "    \"Code smells and clones\",\n",
    "    \"Fuzzing: techniques and tools\",\n",
    "    \"Software architectures and design\",\n",
    "    \"Software security and privacy\",\n",
    "    \"AI systems engineering\",\n",
    "    \"Debugging\",\n",
    "    \"Defect analysis\",\n",
    "    \"Developers' behaviors\",\n",
    "    \"Program translation and synthesis\",\n",
    "    \"Posters\",\n",
    "    \"Documentation\",\n",
    "    \"Software logging\",\n",
    "    \"Test generation\",\n",
    "    \"SE for security\",\n",
    "    \"Development and evolution of AI-intensive systems\",\n",
    "    \"Vulnerability analysis and assessment\",\n",
    "    \"Defect detection and prediction\",\n",
    "    \"Studies on gender in SE\",\n",
    "    \"AI testing\",\n",
    "    \"Code review\",\n",
    "    \"Program repair techniques and applications\",\n",
    "    \"Requirements elicitation and understanding\",\n",
    "    \"Software verification\",\n",
    "    \"Testing of mobile, web and games\",\n",
    "    \"Recommender systems\",\n",
    "    \"Program repair with and for AI\",\n",
    "    \"Programming languages\",\n",
    "    \"AI bias and fairness\",\n",
    "    \"Requirements engineering\",\n",
    "    \"Software Evolution\",\n",
    "    \"Test quality and improvement\",\n",
    "    \"Runtime analysis and self-adaptation\",\n",
    "    \"Developers' forums\",\n",
    "    \"Program comprehension\",\n",
    "    \"Reverse engineering\",\n",
    "    \"Software processes\",\n",
    "    \"Static analysis\",\n",
    "    \"Testing of database and low-level software\",\n",
    "    \"Software performance\",\n",
    "    \"Code generation\",\n",
    "    \"Software development tools\",\n",
    "    \"Fault injection and mutation\",\n",
    "    \"Vulnerability detection\",\n",
    "    \"Issue reporting and reproduction\",\n",
    "    \"Software quality\",\n",
    "    \"SE education methods and tools\",\n",
    "    \"Metamorphic testing\",\n",
    "    \"Pre-trained and few shot learning for SE\",\n",
    "    \"Program analysis\",\n",
    "    \"Vulnerability testing and patching\",\n",
    "    \"Cyber-physical systems testing\",\n",
    "    \"Software ecosystems\",\n",
    "    \"AI & Security\",\n",
    "    \"Evolution & AI\",\n",
    "    \"Testing\",\n",
    "    \"Analysis\",\n",
    "    \"Human and Social\",\n",
    "    \"Generative AI studies\",\n",
    "    \"Language Models and Generated Code\",\n",
    "    \"Program Repair\",\n",
    "    \"Analytics\",\n",
    "    \"Security\",\n",
    "    \"Evolution\",\n",
    "    \"Analysis and Debugging\",\n",
    "    \"LLM, NN and other AI technologies\",\n",
    "    \"Dependability and Formal methods\",\n",
    "    \"Analytics & AI\",\n",
    "    \"Program binaries - evolvability\",\n",
    "    \"Testing: various bug types\",\n",
    "    \"Human and Social Aspects, and Requirements\",\n",
    "    \"Fuzzing\",\n",
    "    \"Requirements\",\n",
    "    \"Testing with and for AI\",\n",
    "    \"Vulnerability Detection\",\n",
    "    \"Static Detection Techniques\",\n",
    "    \"Testing of AI systems\",\n",
    "    \"Human Aspects\",\n",
    "    \"Machine Learning\",\n",
    "    \"Automated Repair\",\n",
    "    \"Empirical Studies\",\n",
    "    \"Program Analysis\",\n",
    "    \"Code Search and Text to Code\",\n",
    "    \"Log Analysis and Debugging\",\n",
    "    \"Fault Diagnosis and Root Cause Analysis\",\n",
    "    \"Clone and Similarity Detection\",\n",
    "    \"Performance\",\n",
    "    \"Formal Verification\",\n",
    "    \"Models of Code and Documentation\",\n",
    "    \"Software Maintenance and Comprehension\",\n",
    "    \"Code Search and Completion\",\n",
    "    \"Processes, Requirements, and Architecture\",\n",
    "    \"AI4SE\",\n",
    "    \"Program Analysis and Performance\",\n",
    "    \"Program Repair and Synthesis\",\n",
    "    \"SE4AI\",\n",
    "    \"Security and Privacy\",\n",
    "    \"Welcome to Day\",\n",
    "    \"AI for SE\",\n",
    "    \"Debugging and Troubleshooting\",\n",
    "    \"Mobile Apps\",\n",
    "    \"Code Analysis\",\n",
    "    \"Source Code Manipulation\",\n",
    "    \"Builds and Versions\",\n",
    "    \"Analysis and Types\",\n",
    "    \"Application Domains\",\n",
    "    \"Bug Prediction and Localization\",\n",
    "    \"Compilers and Languages\",\n",
    "    \"Software Vulnerabilities\",\n",
    "    \"Formal Methods and Models\",\n",
    "    \"SE for AI\",\n",
    "    \"Web, Cloud, Networking\",\n",
    "    \"Code Summarization and Recommendation\",\n",
    "    \"Software Repairs\",\n",
    "    \"Dynamic and Concolic Analysis\",\n",
    "    \"Safety-Critical and Self-Adaptive Systems\",\n",
    "    \"Code Similarities and Refactoring\",\n",
    "    \"Builds and Dependencies\",\n",
    "    \"Cloud and Distributed Systems\",\n",
    "    \"Testing AI Systems\",\n",
    "    \"Infrastructure, Build, and Logs\",\n",
    "    \"Open Source and Software Ecosystems\",\n",
    "    \"Smart Contracts, Blockchain, Energy efficiency, and green software\",\n",
    "    \"Vulnerability and Security\",\n",
    "    \"Code Generation\",\n",
    "    \"Web Development\",\n",
    "    \"Testing Tools and Techniques\",\n",
    "    \"Code Quality and Code Smells\",\n",
    "    \"Code Summarization\",\n",
    "    \"Program Verification\",\n",
    "    \"Code Change Analysis\",\n",
    "    \"Software Testing for Specialized Systems\",\n",
    "    \"Bug Detection\",\n",
    "    \"Autonomous Systems and Agents\",\n",
    "    \"Mobile Development\",\n",
    "    \"Configuration and Version Management\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 2:\n",
      " - AI models for SE\n",
      " - Software security and privacy\n",
      " - SE for security\n",
      " - Studies on gender in SE\n",
      " - Pre-trained and few shot learning for SE\n",
      " - AI & Security\n",
      " - Security\n",
      " - Security and Privacy\n",
      " - AI for SE\n",
      " - SE for AI\n",
      " - Vulnerability and Security\n",
      "\n",
      "\n",
      "Group 4:\n",
      " - Fuzzing: applications\n",
      " - Formal verification\n",
      " - Blockchain/smart contracts\n",
      " - Debugging\n",
      " - Defect analysis\n",
      " - Developers' behaviors\n",
      " - Posters\n",
      " - Documentation\n",
      " - Test generation\n",
      " - Vulnerability analysis and assessment\n",
      " - Programming languages\n",
      " - Runtime analysis and self-adaptation\n",
      " - Developers' forums\n",
      " - Reverse engineering\n",
      " - Static analysis\n",
      " - Analysis\n",
      " - Analytics\n",
      " - Analysis and Debugging\n",
      " - Fuzzing\n",
      " - Machine Learning\n",
      " - Empirical Studies\n",
      " - Log Analysis and Debugging\n",
      " - Fault Diagnosis and Root Cause Analysis\n",
      " - Performance\n",
      " - Formal Verification\n",
      " - AI4SE\n",
      " - SE4AI\n",
      " - Welcome to Day\n",
      " - Mobile Apps\n",
      " - Analysis and Types\n",
      " - Application Domains\n",
      " - Web, Cloud, Networking\n",
      " - Dynamic and Concolic Analysis\n",
      "\n",
      "\n",
      "Group 9:\n",
      " - Mining software repositories\n",
      " - Cognitive aspects of software development\n",
      " - Software architectures and design\n",
      " - Software logging\n",
      " - Software verification\n",
      " - Software Evolution\n",
      " - Software processes\n",
      " - Testing of database and low-level software\n",
      " - Software performance\n",
      " - Software quality\n",
      " - Software ecosystems\n",
      " - Software Maintenance and Comprehension\n",
      " - Software Vulnerabilities\n",
      " - Software Repairs\n",
      " - Open Source and Software Ecosystems\n",
      " - Smart Contracts, Blockchain, Energy efficiency, and green software\n",
      " - Software Testing for Specialized Systems\n",
      "\n",
      "\n",
      "Group 7:\n",
      " - Fault localization\n",
      " - Testing: various bug types\n",
      " - Bug Prediction and Localization\n",
      " - Bug Detection\n",
      "\n",
      "\n",
      "Group 6:\n",
      " - APIs and libraries\n",
      " - Requirements elicitation and understanding\n",
      " - Requirements engineering\n",
      " - Test quality and improvement\n",
      " - Fault injection and mutation\n",
      " - Issue reporting and reproduction\n",
      " - Human and Social\n",
      " - Human and Social Aspects, and Requirements\n",
      " - Requirements\n",
      " - Human Aspects\n",
      " - Processes, Requirements, and Architecture\n",
      " - Debugging and Troubleshooting\n",
      " - Builds and Versions\n",
      " - Compilers and Languages\n",
      " - Builds and Dependencies\n",
      " - Infrastructure, Build, and Logs\n",
      " - Configuration and Version Management\n",
      "\n",
      "\n",
      "Group 5:\n",
      " - Code smells and clones\n",
      " - Code review\n",
      " - Code generation\n",
      " - Language Models and Generated Code\n",
      " - Code Search and Text to Code\n",
      " - Models of Code and Documentation\n",
      " - Code Search and Completion\n",
      " - Code Analysis\n",
      " - Source Code Manipulation\n",
      " - Code Summarization and Recommendation\n",
      " - Code Similarities and Refactoring\n",
      " - Code Generation\n",
      " - Code Quality and Code Smells\n",
      " - Code Summarization\n",
      " - Code Change Analysis\n",
      "\n",
      "\n",
      "Group 0:\n",
      " - Fuzzing: techniques and tools\n",
      " - Software development tools\n",
      " - SE education methods and tools\n",
      " - Dependability and Formal methods\n",
      " - Formal Methods and Models\n",
      " - Testing Tools and Techniques\n",
      "\n",
      "\n",
      "Group 1:\n",
      " - AI systems engineering\n",
      " - Development and evolution of AI-intensive systems\n",
      " - AI testing\n",
      " - Testing of mobile, web and games\n",
      " - Recommender systems\n",
      " - AI bias and fairness\n",
      " - Metamorphic testing\n",
      " - Vulnerability testing and patching\n",
      " - Cyber-physical systems testing\n",
      " - Evolution & AI\n",
      " - Testing\n",
      " - Generative AI studies\n",
      " - Evolution\n",
      " - LLM, NN and other AI technologies\n",
      " - Analytics & AI\n",
      " - Testing with and for AI\n",
      " - Testing of AI systems\n",
      " - Safety-Critical and Self-Adaptive Systems\n",
      " - Cloud and Distributed Systems\n",
      " - Testing AI Systems\n",
      " - Web Development\n",
      " - Autonomous Systems and Agents\n",
      " - Mobile Development\n",
      "\n",
      "\n",
      "Group 3:\n",
      " - Program translation and synthesis\n",
      " - Program repair techniques and applications\n",
      " - Program repair with and for AI\n",
      " - Program comprehension\n",
      " - Program analysis\n",
      " - Program Repair\n",
      " - Program binaries - evolvability\n",
      " - Automated Repair\n",
      " - Program Analysis\n",
      " - Program Analysis and Performance\n",
      " - Program Repair and Synthesis\n",
      " - Program Verification\n",
      "\n",
      "\n",
      "Group 8:\n",
      " - Defect detection and prediction\n",
      " - Vulnerability detection\n",
      " - Vulnerability Detection\n",
      " - Static Detection Techniques\n",
      " - Clone and Similarity Detection\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group sessions by semantics with 10 clusters\n",
    "grouped_sessions = group_sessions_by_semantics(session_names, n_clusters=10)\n",
    "\n",
    "# Print grouped sessions\n",
    "for group_id, sessions in grouped_sessions.items():\n",
    "    print(f\"Group {group_id}:\")\n",
    "    for session in sessions:\n",
    "        print(f\" - {session}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conferences_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
