{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of the sessions and the corresponding papers/talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of the content of papers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sessions_papers(url):\n",
    "    \"\"\"\n",
    "    Extracts session and paper details from a given conference URL on researchr.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the conference page from which to extract data.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are session names and the values are dictionaries containing paper details.\n",
    "              Each paper detail dictionary contains:\n",
    "              - 'name': The title of the paper (str)\n",
    "              - 'authors': A list of authors' names (list of str)\n",
    "              - 'url': The URL to the paper (str)\n",
    "    \"\"\"\n",
    "    # Set up Chrome options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "\n",
    "    # Set up the Chrome WebDriver using ChromeDriverManager\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    # Open the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to fully load (adjust time as needed)\n",
    "    time.sleep(5)  # Increased wait time to ensure the page is fully loaded\n",
    "\n",
    "    # Get the page source after JavaScript has rendered\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # Parse the page content with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Find all divs with the classes 'hidable' and 'band'\n",
    "    all_divs = soup.find_all(\"div\", class_=[\"hidable\", \"band\"])\n",
    "\n",
    "    # Filter for only visible divs\n",
    "    visible_divs = [div for div in all_divs if div.get(\"data-is-visible\") == \"true\"]\n",
    "\n",
    "    # Initialize the dictionary to store sessions with additional details\n",
    "    sessions_details = {}\n",
    "\n",
    "    # Iterate over each visible div\n",
    "    for visible_div in visible_divs:\n",
    "        # Find the session table inside the div\n",
    "        session_table = visible_div.find(\"table\", class_=\"session-table\")\n",
    "        \n",
    "        if session_table:\n",
    "            # Find the tbody element\n",
    "            tbody = session_table.find(\"tbody\")\n",
    "            \n",
    "            if tbody:\n",
    "                # Find the session name\n",
    "                session_info_elem = tbody.find(class_=\"session-info-in-table\")\n",
    "                if session_info_elem:\n",
    "                    # Extract only the first part of the text before the <span> tag\n",
    "                    session_name_parts = session_info_elem.contents\n",
    "                    session_name = \"\"\n",
    "                    \n",
    "                    for part in session_name_parts:\n",
    "                        if isinstance(part, str):  # Check if part is a string (text node)\n",
    "                            session_name += part.strip()  # Append the text part\n",
    "                            break  # Stop after the first text node\n",
    "\n",
    "                session_name = session_name if session_name else \"Unknown Session\"\n",
    "                \n",
    "                # Find all rows (tr elements) within the tbody\n",
    "                rows = tbody.find_all(\"tr\")\n",
    "                \n",
    "                # Papers start from the third row, so we skip the first two\n",
    "                paper_rows = rows[2:]\n",
    "                \n",
    "                # Extract the papers from the remaining rows, checking for visibility\n",
    "                papers = []\n",
    "                for row in paper_rows:\n",
    "                    if row.get(\"data-is-visible\") == \"true\" and row.get(\"style\") != \"display: none;\":\n",
    "                        # Extract the paper name from the 4th td element\n",
    "                        td_elements = row.find_all(\"td\")\n",
    "                        if len(td_elements) >= 4:\n",
    "                            #paper_name_elem = td_elements[3].find(\"strong\")\n",
    "                            #paper_name = paper_name_elem.get_text(strip=True) if paper_name_elem else \"Unknown Paper\"\n",
    "                            paper_name_elem = td_elements[3].find(\"strong\")\n",
    "                            if paper_name_elem:\n",
    "                                # Extract text directly from the <a> tag's first child\n",
    "                                paper_name = paper_name_elem.a.contents[0].strip()\n",
    "                            else:\n",
    "                                paper_name = \"Unknown Paper\"\n",
    "                                                    \n",
    "                            # Extract authors\n",
    "                            authors_div = td_elements[3].find(\"div\", class_=\"performers\")\n",
    "                            authors = [a.get_text(strip=True) for a in authors_div.find_all(\"a\")] if authors_div else []\n",
    "\n",
    "                            # Extract paper URL\n",
    "                            url_elem = td_elements[3].find(\"a\", class_=\"publication-link\")\n",
    "                            paper_url = url_elem['href'] if url_elem else \"No URL available\"\n",
    "                            \n",
    "                            papers.append({\n",
    "                                \"name\": paper_name,\n",
    "                                \"authors\": authors,\n",
    "                                \"url\": paper_url\n",
    "                            })\n",
    "                \n",
    "                # Store the session details in the dictionary\n",
    "                if papers:\n",
    "                    sessions_details[session_name] = {\n",
    "                        \"papers\": papers\n",
    "                    }\n",
    "    \n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    return sessions_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sessions_and_papers(conference_dict):\n",
    "    \"\"\"\n",
    "    Prints details of sessions and their associated papers.\n",
    "\n",
    "    Parameters:\n",
    "    conference_dict (dict): A dictionary where keys are session names and values are dictionaries with papers.\n",
    "    \"\"\"\n",
    "    for session_name, details in conference_dict.items():\n",
    "        print(f\"Session: {session_name}\")\n",
    "        for paper in details['papers']:\n",
    "            print(f\" - Paper: {paper['name']}\")\n",
    "            print(f\"   Authors: {', '.join(paper['authors'])}\")\n",
    "            print(f\"   URL: {paper['url']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_session_names(conference_dict):\n",
    "    \"\"\"\n",
    "    Prints the names of sessions from a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    conference_dict (dict): A dictionary where keys are session names.\n",
    "    \"\"\"\n",
    "    for session_name in conference_dict.keys():\n",
    "        print(f\"{session_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roman_to_int(roman):\n",
    "    \"\"\"\n",
    "    Converts a Roman numeral to an integer. This function only converts Roman numerals \n",
    "    that are standalone, preceded and followed by spaces or are at the start/end of the string.\n",
    "\n",
    "    Parameters:\n",
    "    roman (str): A Roman numeral as a string.\n",
    "\n",
    "    Returns:\n",
    "    int: The integer representation of the Roman numeral, or None if the input is not a valid standalone Roman numeral.\n",
    "    \"\"\"\n",
    "    roman_numerals = {\n",
    "        'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, \n",
    "        'D': 500, 'M': 1000\n",
    "    }\n",
    "    \n",
    "    # Regex pattern to match a valid Roman numeral surrounded by spaces or at the boundaries\n",
    "    pattern = re.compile(r'(^|\\s)(I{1,3}|IV|VI{0,3}|IX|X{1,3}|XL|L?X{0,3}|XC|C{1,3}|CD|D?C{0,3}|CM|M{0,3})(\\s|$)')\n",
    "    \n",
    "    # Find if the input matches the Roman numeral pattern\n",
    "    match = pattern.match(roman)\n",
    "    \n",
    "    if not match:\n",
    "        return None\n",
    "    \n",
    "    roman = match.group(2)  # Extract the Roman numeral part from the match\n",
    "\n",
    "    # Convert Roman numeral to integer\n",
    "    total = 0\n",
    "    prev_value = 0\n",
    "    for char in reversed(roman):\n",
    "        value = roman_numerals.get(char, 0)\n",
    "        if value < prev_value:\n",
    "            total -= value\n",
    "        else:\n",
    "            total += value\n",
    "        prev_value = value\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sessions_by_name(conference_dict):\n",
    "    \"\"\"\n",
    "    Merges sessions with the same base topic into a single session, e.g. \"Testing 1\" and \"Testing II\".\n",
    "\n",
    "    This function consolidates multiple sessions that share the same base topic but differ in their numbering \n",
    "    (either Arabic or Roman numerals) into a single session. It uses regular expressions to identify sessions \n",
    "    with similar base names, combines their associated papers, and returns a dictionary where each key \n",
    "    represents a unique base session name with all its associated papers aggregated.\n",
    "\n",
    "    Parameters:\n",
    "    conference_dict (dict): A dictionary where:\n",
    "        - The keys are session names (strings), which may include a base topic and an optional number suffix (e.g., \"Testing 1\", \"Testing II\").\n",
    "        - The values are dictionaries with a key 'papers', which maps to a list of dictionaries. Each dictionary in the 'papers' list contains:\n",
    "            - 'name' (str): The title of the paper.\n",
    "            - 'authors' (list of str): A list of authors of the paper.\n",
    "            - 'url' (str): The URL to access the paper.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where:\n",
    "        - The keys are base session names (strings) derived from the input session names.\n",
    "        - The values are dictionaries with a key 'papers' that contains a list of all papers associated with that base session name.\n",
    "\n",
    "    \"\"\"\n",
    "    # Dictionary to group papers by session base name\n",
    "    merged_sessions = defaultdict(lambda: {'papers': []})\n",
    "    \n",
    "    # Regular expression to extract base name and number (either Arabic or Roman numerals)\n",
    "    pattern = re.compile(r'^(.*?)(?:\\s+(\\d+|[IVXLCDM]+))?$')\n",
    "    \n",
    "    for session_name, details in conference_dict.items():\n",
    "        # Extract the base name and number using regex\n",
    "        match = pattern.match(session_name)\n",
    "        if match:\n",
    "            base_name = match.group(1).strip()\n",
    "            num_suffix = match.group(2).strip() if match.group(2) else ''\n",
    "            \n",
    "            # Convert Roman numerals to integers for consistency, if applicable\n",
    "            if re.match(r'^[IVXLCDM]+$', num_suffix):\n",
    "                num_suffix = roman_to_int(num_suffix)\n",
    "            else:\n",
    "                num_suffix = int(num_suffix) if num_suffix.isdigit() else None\n",
    "            \n",
    "            # Append papers to the corresponding base name in the merged_sessions\n",
    "            merged_sessions[base_name]['papers'].extend(details['papers'])\n",
    "    \n",
    "    # Convert defaultdict to a regular dict\n",
    "    return dict(merged_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix_of_sessions(conference_dict):\n",
    "    \"\"\"\n",
    "    Cleans the session names in the dictionary by removing the prefix 'Technical Session' along with its number and \n",
    "    the dash ('-'). Only the part after the dash ('-') is kept as the session name.\n",
    "\n",
    "    Parameters:\n",
    "    conference_dict (dict): A dictionary where:\n",
    "        - The keys are session names (strings), which may include 'Technical Session', a number, and a dash ('-') prefix.\n",
    "        - The values are dictionaries with a key 'papers', which maps to a list of dictionaries. Each dictionary in the 'papers' list contains:\n",
    "            - 'name' (str): The title of the paper.\n",
    "            - 'authors' (list of str): A list of authors of the paper.\n",
    "            - 'url' (str): The URL to access the paper.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where:\n",
    "        - The keys are cleaned session names (strings), derived from the input session names.\n",
    "        - The values are dictionaries with a key 'papers' that contains a list of all papers associated with that cleaned session name.\n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_sessions = {}\n",
    "    \n",
    "    # Regular expression to match 'Technical Session' followed by a number and a dash\n",
    "    pattern = re.compile(r'^Technical Session \\d+ - (.+)$')\n",
    "\n",
    "    for session_name, details in conference_dict.items():\n",
    "        # Check if session name matches the pattern\n",
    "        match = pattern.match(session_name)\n",
    "        if match:\n",
    "            # Extract and clean the session name\n",
    "            cleaned_name = match.group(1).strip()\n",
    "        else:\n",
    "            # Keep the original name if it does not match the pattern\n",
    "            cleaned_name = session_name\n",
    "        \n",
    "        # Add the papers to the cleaned session name\n",
    "        if cleaned_name in cleaned_sessions:\n",
    "            cleaned_sessions[cleaned_name]['papers'].extend(details['papers'])\n",
    "        else:\n",
    "            cleaned_sessions[cleaned_name] = details\n",
    "    \n",
    "    return cleaned_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sessions(dicts):\n",
    "    \"\"\"\n",
    "    Merge multiple dictionaries containing session and paper details based on exact session names.\n",
    "    \n",
    "    Args:\n",
    "        dicts (list of dict): List of dictionaries where each dictionary contains sessions and their papers.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A merged dictionary with session names as keys and combined paper details as values.\n",
    "    \"\"\"\n",
    "    # Dictionary to hold the merged results\n",
    "    merged_sessions = defaultdict(lambda: {\"papers\": []})\n",
    "    \n",
    "    for session_dict in dicts:\n",
    "        for session_name, details in session_dict.items():\n",
    "            # Add the papers to the merged_sessions dictionary under the exact session name\n",
    "            merged_sessions[session_name][\"papers\"].extend(details[\"papers\"])\n",
    "    \n",
    "    # Convert defaultdict to a regular dict\n",
    "    return dict(merged_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASE 2022-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASE 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ASE 2023 36 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ase2023_url = \"https://conf.researchr.org/track/ase-2023/ase-2023-papers?track=ASE%20Research%20Papers#program\"\n",
    "ase2023 = extract_sessions_papers(ase2023_url)\n",
    "\n",
    "print(\"Sessions in ASE 2023\", len(ase2023), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_sessions_and_papers(ase2023)\n",
    "#print_session_names(ase2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ASE 2023 after cleaning 22 \n",
      "\n",
      "Cloud and Distributed Systems\n",
      "Testing AI Systems\n",
      "Infrastructure, Build, and Logs\n",
      "Open Source and Software Ecosystems\n",
      "Smart Contracts, Blockchain, Energy efficiency, and green software\n",
      "Vulnerability and Security\n",
      "Code Generation\n",
      "Web Development\n",
      "Testing Tools and Techniques\n",
      "Code Quality and Code Smells\n",
      "Program Repair\n",
      "Program Analysis\n",
      "Code Summarization\n",
      "Program Verification\n",
      "Code Change Analysis\n",
      "Software Testing for Specialized Systems\n",
      "Bug Detection\n",
      "Autonomous Systems and Agents\n",
      "Mobile Development\n",
      "Debugging\n",
      "Fuzzing\n",
      "Configuration and Version Management\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "ase2023_cleaned = merge_sessions_by_name(ase2023)\n",
    "\n",
    "print(\"Sessions in ASE 2023 after cleaning\", len(ase2023_cleaned), \"\\n\")\n",
    "\n",
    "print_session_names(ase2023_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASE 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ASE 2022 35 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ase2022_url = \"https://conf.researchr.org/program/ase-2022/program-ase-2022/?track=ASE%20Research%20Papers\"\n",
    "ase2022 = extract_sessions_papers(ase2022_url)\n",
    "\n",
    "print(\"Sessions in ASE 2022\", len(ase2022), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ase2022_noprefix = remove_prefix_of_sessions(ase2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ASE 2022 after cleaning 26 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "ase2022_cleaned = merge_sessions_by_name(ase2022_noprefix)\n",
    "\n",
    "print(\"Sessions in ASE 2022 after cleaning\", len(ase2022_cleaned), \"\\n\")\n",
    "\n",
    "#print_session_names(ase2022_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge both ASE dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in both ASE dictionaries 47 \n",
      "\n",
      "Welcome to Day\n",
      "AI for SE\n",
      "Debugging and Troubleshooting\n",
      "Fuzzing\n",
      "Mobile Apps\n",
      "Code Analysis\n",
      "Source Code Manipulation\n",
      "Security and Privacy\n",
      "Testing\n",
      "Builds and Versions\n",
      "Analysis and Types\n",
      "Application Domains\n",
      "Bug Prediction and Localization\n",
      "Compilers and Languages\n",
      "Software Vulnerabilities\n",
      "Formal Methods and Models\n",
      "SE for AI\n",
      "Web, Cloud, Networking\n",
      "Security\n",
      "Code Summarization and Recommendation\n",
      "Human Aspects\n",
      "Software Repairs\n",
      "Dynamic and Concolic Analysis\n",
      "Safety-Critical and Self-Adaptive Systems\n",
      "Code Similarities and Refactoring\n",
      "Builds and Dependencies\n",
      "Cloud and Distributed Systems\n",
      "Testing AI Systems\n",
      "Infrastructure, Build, and Logs\n",
      "Open Source and Software Ecosystems\n",
      "Smart Contracts, Blockchain, Energy efficiency, and green software\n",
      "Vulnerability and Security\n",
      "Code Generation\n",
      "Web Development\n",
      "Testing Tools and Techniques\n",
      "Code Quality and Code Smells\n",
      "Program Repair\n",
      "Program Analysis\n",
      "Code Summarization\n",
      "Program Verification\n",
      "Code Change Analysis\n",
      "Software Testing for Specialized Systems\n",
      "Bug Detection\n",
      "Autonomous Systems and Agents\n",
      "Mobile Development\n",
      "Debugging\n",
      "Configuration and Version Management\n"
     ]
    }
   ],
   "source": [
    "# Merging the dictionaries\n",
    "merged_dict_ase = merge_sessions([ase2022_cleaned, ase2023_cleaned])\n",
    "\n",
    "print(\"Sessions in both ASE dictionaries\", len(merged_dict_ase), \"\\n\")\n",
    "\n",
    "#print_sessions_and_papers(merged_dict)\n",
    "print_session_names(merged_dict_ase)\n",
    "\n",
    "#print(merged_dict_ase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSE 2023-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSE 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in FSE 2024 32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fse2024_url = \"https://2024.esec-fse.org/program/program-fse-2024/?track=FSE%20Research%20Papers\"\n",
    "fse2024 = extract_sessions_papers(fse2024_url)\n",
    "\n",
    "print(\"Sessions in FSE 2024\", len(fse2024), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_sessions_and_papers(fse2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in FSE 2024 after cleaning 15 \n",
      "\n",
      "Software Maintenance and Comprehension\n",
      "Human Aspects\n",
      "Formal Verification\n",
      "Code Search and Completion\n",
      "Processes, Requirements, and Architecture\n",
      "Empirical Studies\n",
      "Testing\n",
      "AI4SE\n",
      "Program Analysis and Performance\n",
      "Program Repair and Synthesis\n",
      "Fault Diagnosis and Root Cause Analysis\n",
      "SE4AI\n",
      "Security and Privacy\n",
      "Log Analysis and Debugging\n",
      "Fuzzing\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "fse2024_cleaned = merge_sessions_by_name(fse2024)\n",
    "\n",
    "print(\"Sessions in FSE 2024 after cleaning\", len(fse2024_cleaned), \"\\n\")\n",
    "\n",
    "print_session_names(fse2024_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSE 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in FSE 2023 32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fse2023_url = \"https://2023.esec-fse.org/program/program-fse-2023/?track=ESEC%2FFSE%20Research%20Papers\"\n",
    "\n",
    "fse2023 = extract_sessions_papers(fse2023_url)\n",
    "\n",
    "print(\"Sessions in FSE 2023\", len(fse2023), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_sessions_and_papers(fse2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in FSE 2023 after cleaning 16 \n",
      "\n",
      "Human Aspects\n",
      "Testing\n",
      "Machine Learning\n",
      "Automated Repair\n",
      "Empirical Studies\n",
      "Software Evolution\n",
      "Program Analysis\n",
      "Code Search and Text to Code\n",
      "Log Analysis and Debugging\n",
      "Fault Diagnosis and Root Cause Analysis\n",
      "Clone and Similarity Detection\n",
      "Performance\n",
      "Security\n",
      "Fuzzing\n",
      "Formal Verification\n",
      "Models of Code and Documentation\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "fse2023_cleaned = merge_sessions_by_name(fse2023)\n",
    "\n",
    "print(\"Sessions in FSE 2023 after cleaning\", len(fse2023_cleaned), \"\\n\")\n",
    "\n",
    "print_session_names(fse2023_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge both FSE dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in both FSE dictionaries 24 \n",
      "\n",
      "Human Aspects\n",
      "Testing\n",
      "Machine Learning\n",
      "Automated Repair\n",
      "Empirical Studies\n",
      "Software Evolution\n",
      "Program Analysis\n",
      "Code Search and Text to Code\n",
      "Log Analysis and Debugging\n",
      "Fault Diagnosis and Root Cause Analysis\n",
      "Clone and Similarity Detection\n",
      "Performance\n",
      "Security\n",
      "Fuzzing\n",
      "Formal Verification\n",
      "Models of Code and Documentation\n",
      "Software Maintenance and Comprehension\n",
      "Code Search and Completion\n",
      "Processes, Requirements, and Architecture\n",
      "AI4SE\n",
      "Program Analysis and Performance\n",
      "Program Repair and Synthesis\n",
      "SE4AI\n",
      "Security and Privacy\n"
     ]
    }
   ],
   "source": [
    "# Merging the dictionaries\n",
    "merged_dict_fse = merge_sessions([fse2023_cleaned, fse2024_cleaned])\n",
    "\n",
    "print(\"Sessions in both FSE dictionaries\", len(merged_dict_fse), \"\\n\")\n",
    "\n",
    "#print_sessions_and_papers(merged_dict)\n",
    "print_session_names(merged_dict_fse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICSE 2023-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICSE 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ICSE 2024:  71 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "icse2024_url = \"https://conf.researchr.org/program/icse-2024/program-icse-2024/?track=ICSE%20Research%20Track\"\n",
    "icse2024 = extract_sessions_papers(icse2024_url)\n",
    "\n",
    "print(\"Sessions in ICSE 2024: \", len(icse2024), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ICSE 2024 after cleaning 24 \n",
      "\n",
      "AI & Security\n",
      "Evolution & AI\n",
      "Testing\n",
      "Analysis\n",
      "Human and Social\n",
      "Generative AI studies\n",
      "Language Models and Generated Code\n",
      "Program Repair\n",
      "Analytics\n",
      "Security\n",
      "Evolution\n",
      "Analysis and Debugging\n",
      "LLM, NN and other AI technologies\n",
      "Dependability and Formal methods\n",
      "Analytics & AI\n",
      "Program binaries - evolvability\n",
      "Testing: various bug types\n",
      "Human and Social Aspects, and Requirements\n",
      "Fuzzing\n",
      "Requirements\n",
      "Testing with and for AI\n",
      "Vulnerability Detection\n",
      "Static Detection Techniques\n",
      "Testing of AI systems\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "icse2024_cleaned = merge_sessions_by_name(icse2024)\n",
    "\n",
    "print(\"Sessions in ICSE 2024 after cleaning\", len(icse2024_cleaned), \"\\n\")\n",
    "\n",
    "print_session_names(icse2024_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICSE 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ICSE 2023 63 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "icse2023_url = \"https://conf.researchr.org/program/icse-2023/program-icse-2023/?track=ICSE%20Technical%20Track\"\n",
    "icse2023 = extract_sessions_papers(icse2023_url)\n",
    "\n",
    "print(\"Sessions in ICSE 2023\", len(icse2023), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in ICSE 2023 after cleaning 60 \n",
      "\n",
      "AI models for SE\n",
      "Fuzzing: applications\n",
      "Mining software repositories\n",
      "Fault localization\n",
      "Formal verification\n",
      "APIs and libraries\n",
      "Blockchain/smart contracts\n",
      "Cognitive aspects of software development\n",
      "Code smells and clones\n",
      "Fuzzing: techniques and tools\n",
      "Software architectures and design\n",
      "Software security and privacy\n",
      "AI systems engineering\n",
      "Debugging\n",
      "Defect analysis\n",
      "Developers' behaviors\n",
      "Program translation and synthesis\n",
      "Posters\n",
      "Documentation\n",
      "Software logging\n",
      "Test generation\n",
      "SE for security\n",
      "Development and evolution of AI-intensive systems\n",
      "Vulnerability analysis and assessment\n",
      "Defect detection and prediction\n",
      "Studies on gender in SE\n",
      "AI testing\n",
      "Code review\n",
      "Program repair techniques and applications\n",
      "Requirements elicitation and understanding\n",
      "Software verification\n",
      "Testing of mobile, web and games\n",
      "Recommender systems\n",
      "Program repair with and for AI\n",
      "Programming languages\n",
      "AI bias and fairness\n",
      "Requirements engineering\n",
      "Software Evolution\n",
      "Test quality and improvement\n",
      "Runtime analysis and self-adaptation\n",
      "Developers' forums\n",
      "Program comprehension\n",
      "Reverse engineering\n",
      "Software processes\n",
      "Static analysis\n",
      "Testing of database and low-level software\n",
      "Software performance\n",
      "Code generation\n",
      "Software development tools\n",
      "Fault injection and mutation\n",
      "Vulnerability detection\n",
      "Issue reporting and reproduction\n",
      "Software quality\n",
      "SE education methods and tools\n",
      "Metamorphic testing\n",
      "Pre-trained and few shot learning for SE\n",
      "Program analysis\n",
      "Vulnerability testing and patching\n",
      "Cyber-physical systems testing\n",
      "Software ecosystems\n"
     ]
    }
   ],
   "source": [
    "# Merge sessions\n",
    "icse2023_cleaned = merge_sessions_by_name(icse2023)\n",
    "\n",
    "print(\"Sessions in ICSE 2023 after cleaning\", len(icse2023_cleaned), \"\\n\")\n",
    "\n",
    "print_session_names(icse2023_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge both ICSE dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in both ICSE dictionaries 84 \n",
      "\n",
      "AI models for SE\n",
      "Fuzzing: applications\n",
      "Mining software repositories\n",
      "Fault localization\n",
      "Formal verification\n",
      "APIs and libraries\n",
      "Blockchain/smart contracts\n",
      "Cognitive aspects of software development\n",
      "Code smells and clones\n",
      "Fuzzing: techniques and tools\n",
      "Software architectures and design\n",
      "Software security and privacy\n",
      "AI systems engineering\n",
      "Debugging\n",
      "Defect analysis\n",
      "Developers' behaviors\n",
      "Program translation and synthesis\n",
      "Posters\n",
      "Documentation\n",
      "Software logging\n",
      "Test generation\n",
      "SE for security\n",
      "Development and evolution of AI-intensive systems\n",
      "Vulnerability analysis and assessment\n",
      "Defect detection and prediction\n",
      "Studies on gender in SE\n",
      "AI testing\n",
      "Code review\n",
      "Program repair techniques and applications\n",
      "Requirements elicitation and understanding\n",
      "Software verification\n",
      "Testing of mobile, web and games\n",
      "Recommender systems\n",
      "Program repair with and for AI\n",
      "Programming languages\n",
      "AI bias and fairness\n",
      "Requirements engineering\n",
      "Software Evolution\n",
      "Test quality and improvement\n",
      "Runtime analysis and self-adaptation\n",
      "Developers' forums\n",
      "Program comprehension\n",
      "Reverse engineering\n",
      "Software processes\n",
      "Static analysis\n",
      "Testing of database and low-level software\n",
      "Software performance\n",
      "Code generation\n",
      "Software development tools\n",
      "Fault injection and mutation\n",
      "Vulnerability detection\n",
      "Issue reporting and reproduction\n",
      "Software quality\n",
      "SE education methods and tools\n",
      "Metamorphic testing\n",
      "Pre-trained and few shot learning for SE\n",
      "Program analysis\n",
      "Vulnerability testing and patching\n",
      "Cyber-physical systems testing\n",
      "Software ecosystems\n",
      "AI & Security\n",
      "Evolution & AI\n",
      "Testing\n",
      "Analysis\n",
      "Human and Social\n",
      "Generative AI studies\n",
      "Language Models and Generated Code\n",
      "Program Repair\n",
      "Analytics\n",
      "Security\n",
      "Evolution\n",
      "Analysis and Debugging\n",
      "LLM, NN and other AI technologies\n",
      "Dependability and Formal methods\n",
      "Analytics & AI\n",
      "Program binaries - evolvability\n",
      "Testing: various bug types\n",
      "Human and Social Aspects, and Requirements\n",
      "Fuzzing\n",
      "Requirements\n",
      "Testing with and for AI\n",
      "Vulnerability Detection\n",
      "Static Detection Techniques\n",
      "Testing of AI systems\n"
     ]
    }
   ],
   "source": [
    "# Merging the dictionaries\n",
    "merged_dict_icse = merge_sessions([icse2023_cleaned, icse2024_cleaned])\n",
    "\n",
    "print(\"Sessions in both ICSE dictionaries\", len(merged_dict_icse), \"\\n\")\n",
    "\n",
    "#print_sessions_and_papers(merged_dict)\n",
    "print_session_names(merged_dict_icse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions in both all dictionaries 143 \n",
      "\n",
      "AI models for SE\n",
      "Fuzzing: applications\n",
      "Mining software repositories\n",
      "Fault localization\n",
      "Formal verification\n",
      "APIs and libraries\n",
      "Blockchain/smart contracts\n",
      "Cognitive aspects of software development\n",
      "Code smells and clones\n",
      "Fuzzing: techniques and tools\n",
      "Software architectures and design\n",
      "Software security and privacy\n",
      "AI systems engineering\n",
      "Debugging\n",
      "Defect analysis\n",
      "Developers' behaviors\n",
      "Program translation and synthesis\n",
      "Posters\n",
      "Documentation\n",
      "Software logging\n",
      "Test generation\n",
      "SE for security\n",
      "Development and evolution of AI-intensive systems\n",
      "Vulnerability analysis and assessment\n",
      "Defect detection and prediction\n",
      "Studies on gender in SE\n",
      "AI testing\n",
      "Code review\n",
      "Program repair techniques and applications\n",
      "Requirements elicitation and understanding\n",
      "Software verification\n",
      "Testing of mobile, web and games\n",
      "Recommender systems\n",
      "Program repair with and for AI\n",
      "Programming languages\n",
      "AI bias and fairness\n",
      "Requirements engineering\n",
      "Software Evolution\n",
      "Test quality and improvement\n",
      "Runtime analysis and self-adaptation\n",
      "Developers' forums\n",
      "Program comprehension\n",
      "Reverse engineering\n",
      "Software processes\n",
      "Static analysis\n",
      "Testing of database and low-level software\n",
      "Software performance\n",
      "Code generation\n",
      "Software development tools\n",
      "Fault injection and mutation\n",
      "Vulnerability detection\n",
      "Issue reporting and reproduction\n",
      "Software quality\n",
      "SE education methods and tools\n",
      "Metamorphic testing\n",
      "Pre-trained and few shot learning for SE\n",
      "Program analysis\n",
      "Vulnerability testing and patching\n",
      "Cyber-physical systems testing\n",
      "Software ecosystems\n",
      "AI & Security\n",
      "Evolution & AI\n",
      "Testing\n",
      "Analysis\n",
      "Human and Social\n",
      "Generative AI studies\n",
      "Language Models and Generated Code\n",
      "Program Repair\n",
      "Analytics\n",
      "Security\n",
      "Evolution\n",
      "Analysis and Debugging\n",
      "LLM, NN and other AI technologies\n",
      "Dependability and Formal methods\n",
      "Analytics & AI\n",
      "Program binaries - evolvability\n",
      "Testing: various bug types\n",
      "Human and Social Aspects, and Requirements\n",
      "Fuzzing\n",
      "Requirements\n",
      "Testing with and for AI\n",
      "Vulnerability Detection\n",
      "Static Detection Techniques\n",
      "Testing of AI systems\n",
      "Human Aspects\n",
      "Machine Learning\n",
      "Automated Repair\n",
      "Empirical Studies\n",
      "Program Analysis\n",
      "Code Search and Text to Code\n",
      "Log Analysis and Debugging\n",
      "Fault Diagnosis and Root Cause Analysis\n",
      "Clone and Similarity Detection\n",
      "Performance\n",
      "Formal Verification\n",
      "Models of Code and Documentation\n",
      "Software Maintenance and Comprehension\n",
      "Code Search and Completion\n",
      "Processes, Requirements, and Architecture\n",
      "AI4SE\n",
      "Program Analysis and Performance\n",
      "Program Repair and Synthesis\n",
      "SE4AI\n",
      "Security and Privacy\n",
      "Welcome to Day\n",
      "AI for SE\n",
      "Debugging and Troubleshooting\n",
      "Mobile Apps\n",
      "Code Analysis\n",
      "Source Code Manipulation\n",
      "Builds and Versions\n",
      "Analysis and Types\n",
      "Application Domains\n",
      "Bug Prediction and Localization\n",
      "Compilers and Languages\n",
      "Software Vulnerabilities\n",
      "Formal Methods and Models\n",
      "SE for AI\n",
      "Web, Cloud, Networking\n",
      "Code Summarization and Recommendation\n",
      "Software Repairs\n",
      "Dynamic and Concolic Analysis\n",
      "Safety-Critical and Self-Adaptive Systems\n",
      "Code Similarities and Refactoring\n",
      "Builds and Dependencies\n",
      "Cloud and Distributed Systems\n",
      "Testing AI Systems\n",
      "Infrastructure, Build, and Logs\n",
      "Open Source and Software Ecosystems\n",
      "Smart Contracts, Blockchain, Energy efficiency, and green software\n",
      "Vulnerability and Security\n",
      "Code Generation\n",
      "Web Development\n",
      "Testing Tools and Techniques\n",
      "Code Quality and Code Smells\n",
      "Code Summarization\n",
      "Program Verification\n",
      "Code Change Analysis\n",
      "Software Testing for Specialized Systems\n",
      "Bug Detection\n",
      "Autonomous Systems and Agents\n",
      "Mobile Development\n",
      "Configuration and Version Management\n"
     ]
    }
   ],
   "source": [
    "# Merging all the dictionaries\n",
    "merged_dict_all = merge_sessions([merged_dict_icse, merged_dict_fse, merged_dict_ase])\n",
    "\n",
    "print(\"Sessions in both all dictionaries\", len(merged_dict_all), \"\\n\")\n",
    "\n",
    "#print_sessions_and_papers(merged_dict_all)\n",
    "print_session_names(merged_dict_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging: Check if the session names inside the dictionary (merged_dict_all) matches with the session names that we have writte in our text file\n",
    "\n",
    "Reason: There was a spelling mistake taht lead to problems in the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI models for SE', 'Fuzzing: applications', 'Mining software repositories', 'Fault localization', 'Formal verification', 'APIs and libraries', 'Blockchain/smart contracts', 'Cognitive aspects of software development', 'Code smells and clones', 'Fuzzing: techniques and tools', 'Software architectures and design', 'Software security and privacy', 'AI systems engineering', 'Debugging', 'Defect analysis', \"Developers' behaviors\", 'Program translation and synthesis', 'Posters', 'Documentation', 'Software logging', 'Test generation', 'SE for security', 'Development and evolution of AI-intensive systems', 'Vulnerability analysis and assessment', 'Defect detection and prediction', 'Studies on gender in SE', 'AI testing', 'Code review', 'Program repair techniques and applications', 'Requirements elicitation and understanding', 'Software verification', 'Testing of mobile, web and games', 'Recommender systems', 'Program repair with and for AI', 'Programming languages', 'AI bias and fairness', 'Requirements engineering', 'Software Evolution', 'Test quality and improvement', 'Runtime analysis and self-adaptation', \"Developers' forums\", 'Program comprehension', 'Reverse engineering', 'Software processes', 'Static analysis', 'Testing of database and low-level software', 'Software performance', 'Code generation', 'Software development tools', 'Fault injection and mutation', 'Vulnerability detection', 'Issue reporting and reproduction', 'Software quality', 'SE education methods and tools', 'Metamorphic testing', 'Pre-trained and few shot learning for SE', 'Program analysis', 'Vulnerability testing and patching', 'Cyber-physical systems testing', 'Software ecosystems', 'AI & Security', 'Evolution & AI', 'Testing', 'Analysis', 'Human and Social', 'Generative AI studies', 'Language Models and Generated Code', 'Program Repair', 'Analytics', 'Security', 'Evolution', 'Analysis and Debugging', 'LLM, NN and other AI technologies', 'Dependability and Formal methods', 'Analytics & AI', 'Program binaries - evolvability', 'Testing: various bug types', 'Human and Social Aspects, and Requirements', 'Fuzzing', 'Requirements', 'Testing with and for AI', 'Vulnerability Detection', 'Static Detection Techniques', 'Testing of AI systems', 'Human Aspects', 'Machine Learning', 'Automated Repair', 'Empirical Studies', 'Program Analysis', 'Code Search and Text to Code', 'Log Analysis and Debugging', 'Fault Diagnosis and Root Cause Analysis', 'Clone and Similarity Detection', 'Performance', 'Formal Verification', 'Models of Code and Documentation', 'Software Maintenance and Comprehension', 'Code Search and Completion', 'Processes, Requirements, and Architecture', 'AI4SE', 'Program Analysis and Performance', 'Program Repair and Synthesis', 'SE4AI', 'Security and Privacy', 'Welcome to Day', 'AI for SE', 'Debugging and Troubleshooting', 'Mobile Apps', 'Code Analysis', 'Source Code Manipulation', 'Builds and Versions', 'Analysis and Types', 'Application Domains', 'Bug Prediction and Localization', 'Compilers and Languages', 'Software Vulnerabilities', 'Formal Methods and Models', 'SE for AI', 'Web, Cloud, Networking', 'Code Summarization and Recommendation', 'Software Repairs', 'Dynamic and Concolic Analysis', 'Safety-Critical and Self-Adaptive Systems', 'Code Similarities and Refactoring', 'Builds and Dependencies', 'Cloud and Distributed Systems', 'Testing AI Systems', 'Infrastructure, Build, and Logs', 'Open Source and Software Ecosystems', 'Smart Contracts, Blockchain, Energy efficiency, and green software', 'Vulnerability and Security', 'Code Generation', 'Web Development', 'Testing Tools and Techniques', 'Code Quality and Code Smells', 'Code Summarization', 'Program Verification', 'Code Change Analysis', 'Software Testing for Specialized Systems', 'Bug Detection', 'Autonomous Systems and Agents', 'Mobile Development', 'Configuration and Version Management']\n",
      "['AI models for SE', 'Fuzzing: applications', 'Mining software repositories', 'Fault localization', 'Formal verification', 'APIs and libraries', 'Blockchain/smart contracts', 'Cognitive aspects of software development', 'Code smells and clones', 'Fuzzing: techniques and tools', 'Software architectures and design', 'Software security and privacy', 'AI systems engineering', 'Debugging', 'Defect analysis', \"Developers' behaviors\", 'Program translation and synthesis', 'Posters', 'Documentation', 'Software logging', 'Test generation', 'SE for security', 'Development and evolution of AI-intensive systems', 'Vulnerability analysis and assessment', 'Defect detection and prediction', 'Studies on gender in SE', 'AI testing', 'Code review', 'Program repair techniques and applications', 'Requirements elicitation and understanding', 'Software verification', 'Testing of mobile, web and games', 'Recommender systems', 'Program repair with and for AI', 'Programming languages', 'AI bias and fairness', 'Requirements engineering', 'Software Evolution', 'Test quality and improvement', 'Runtime analysis and self-adaptation', \"Developers' forums\", 'Program comprehension', 'Reverse engineering', 'Software processes', 'Static analysis', 'Testing of database and low-level software', 'Software performance', 'Code generation', 'Software development tools', 'Fault injection and mutation', 'Vulnerability detection', 'Issue reporting and reproduction', 'Software quality', 'SE education methods and tools', 'Metamorphic testing', 'Pre-trained and few shot learning for SE', 'Program analysis', 'Vulnerability testing and patching', 'Cyber-physical systems testing', 'Software ecosystems', 'AI & Security', 'Evolution & AI', 'Testing', 'Analysis', 'Human and Social', 'Generative AI studies', 'Language Models and Generated Code', 'Program Repair', 'Analytics', 'Security', 'Evolution', 'Analysis and Debugging', 'LLM, NN and other AI technologies', 'Dependability and Formal methods', 'Analytics & AI', 'Program binaries - evolvability', 'Testing: various bug types', 'Human and Social Aspects, and Requirements', 'Fuzzing', 'Requirements', 'Testing with and for AI', 'Vulnerability Detection', 'Static Detection Techniques', 'Testing of AI systems', 'Human Aspects', 'Machine Learning', 'Automated Repair', 'Empirical Studies', 'Program Analysis', 'Code Search and Text to Code', 'Log Analysis and Debugging', 'Fault Diagnosis and Root Cause Analysis', 'Clone and Similarity Detection', 'Performance', 'Formal Verification', 'Models of Code and Documentation', 'Software Maintenance and Comprehension', 'Code Search and Completion', 'Processes, Requirements, and Architecture', 'AI4SE', 'Program Analysis and Performance', 'Program Repair and Synthesis', 'SE4AI', 'Security and Privacy', 'Welcome to Day', 'AI for SE', 'Debugging and Troubleshooting', 'Mobile Apps', 'Code Analysis', 'Source Code Manipulation', 'Builds and Versions', 'Analysis and Types', 'Application Domains', 'Bug Prediction and Localization', 'Compilers and Languages', 'Software Vulnerabilities', 'Formal Methods and Models', 'SE for AI', 'Web, Cloud, Networking', 'Code Summarization and Recommendation', 'Software Repairs', 'Dynamic and Concolic Analysis', 'Safety-Critical and Self-Adaptive Systems', 'Code Similarities and Refactoring', 'Builds and Dependencies', 'Cloud and Distributed Systems', 'Testing AI Systems', 'Infrastructure, Build, and Logs', 'Open Source and Software Ecosystems', 'Smart Contracts, Blockchain, Energy efficiency, and green software', 'Vulnerability and Security', 'Code Generation', 'Web Development', 'Testing Tools and Techniques', 'Code Quality and Code Smells', 'Code Summarization', 'Program Verification', 'Code Change Analysis', 'Software Testing for Specialized Systems', 'Bug Detection', 'Autonomous Systems and Agents', 'Mobile Development', 'Configuration and Version Management']\n"
     ]
    }
   ],
   "source": [
    "list1 = []\n",
    "\n",
    "# Loop through the conference_dict keys and append each session name to list1\n",
    "for session_name in merged_dict_all.keys():\n",
    "    list1.append(session_name)\n",
    "\n",
    "# Print list1 to verify that session names have been saved\n",
    "print(list1)\n",
    "\n",
    "list2 = [\n",
    "    \"AI models for SE\",\n",
    "    \"Fuzzing: applications\",\n",
    "    \"Mining software repositories\",\n",
    "    \"Fault localization\",\n",
    "    \"Formal verification\",\n",
    "    \"APIs and libraries\",\n",
    "    \"Blockchain/smart contracts\",\n",
    "    \"Cognitive aspects of software development\",\n",
    "    \"Code smells and clones\",\n",
    "    \"Fuzzing: techniques and tools\",\n",
    "    \"Software architectures and design\",\n",
    "    \"Software security and privacy\",\n",
    "    \"AI systems engineering\",\n",
    "    \"Debugging\",\n",
    "    \"Defect analysis\",\n",
    "    \"Developers' behaviors\",\n",
    "    \"Program translation and synthesis\",\n",
    "    \"Posters\",\n",
    "    \"Documentation\",\n",
    "    \"Software logging\",\n",
    "    \"Test generation\",\n",
    "    \"SE for security\",\n",
    "    \"Development and evolution of AI-intensive systems\",\n",
    "    \"Vulnerability analysis and assessment\",\n",
    "    \"Defect detection and prediction\",\n",
    "    \"Studies on gender in SE\",\n",
    "    \"AI testing\",\n",
    "    \"Code review\",\n",
    "    \"Program repair techniques and applications\",\n",
    "    \"Requirements elicitation and understanding\",\n",
    "    \"Software verification\",\n",
    "    \"Testing of mobile, web and games\",\n",
    "    \"Recommender systems\",\n",
    "    \"Program repair with and for AI\",\n",
    "    \"Programming languages\",\n",
    "    \"AI bias and fairness\",\n",
    "    \"Requirements engineering\",\n",
    "    \"Software Evolution\",\n",
    "    \"Test quality and improvement\",\n",
    "    \"Runtime analysis and self-adaptation\",\n",
    "    \"Developers' forums\",\n",
    "    \"Program comprehension\",\n",
    "    \"Reverse engineering\",\n",
    "    \"Software processes\",\n",
    "    \"Static analysis\",\n",
    "    \"Testing of database and low-level software\",\n",
    "    \"Software performance\",\n",
    "    \"Code generation\",\n",
    "    \"Software development tools\",\n",
    "    \"Fault injection and mutation\",\n",
    "    \"Vulnerability detection\",\n",
    "    \"Issue reporting and reproduction\",\n",
    "    \"Software quality\",\n",
    "    \"SE education methods and tools\",\n",
    "    \"Metamorphic testing\",\n",
    "    \"Pre-trained and few shot learning for SE\",\n",
    "    \"Program analysis\",\n",
    "    \"Vulnerability testing and patching\",\n",
    "    \"Cyber-physical systems testing\",\n",
    "    \"Software ecosystems\",\n",
    "    \"AI & Security\",\n",
    "    \"Evolution & AI\",\n",
    "    \"Testing\",\n",
    "    \"Analysis\",\n",
    "    \"Human and Social\",\n",
    "    \"Generative AI studies\",\n",
    "    \"Language Models and Generated Code\",\n",
    "    \"Program Repair\",\n",
    "    \"Analytics\",\n",
    "    \"Security\",\n",
    "    \"Evolution\",\n",
    "    \"Analysis and Debugging\",\n",
    "    \"LLM, NN and other AI technologies\",\n",
    "    \"Dependability and Formal methods\",\n",
    "    \"Analytics & AI\",\n",
    "    \"Program binaries - evolvability\",\n",
    "    \"Testing: various bug types\",\n",
    "    \"Human and Social Aspects, and Requirements\",\n",
    "    \"Fuzzing\",\n",
    "    \"Requirements\",\n",
    "    \"Testing with and for AI\",\n",
    "    \"Vulnerability Detection\",\n",
    "    \"Static Detection Techniques\",\n",
    "    \"Testing of AI systems\",\n",
    "    \"Human Aspects\",\n",
    "    \"Machine Learning\",\n",
    "    \"Automated Repair\",\n",
    "    \"Empirical Studies\",\n",
    "    \"Program Analysis\",\n",
    "    \"Code Search and Text to Code\",\n",
    "    \"Log Analysis and Debugging\",\n",
    "    \"Fault Diagnosis and Root Cause Analysis\",\n",
    "    \"Clone and Similarity Detection\",\n",
    "    \"Performance\",\n",
    "    \"Formal Verification\",\n",
    "    \"Models of Code and Documentation\",\n",
    "    \"Software Maintenance and Comprehension\",\n",
    "    \"Code Search and Completion\",\n",
    "    \"Processes, Requirements, and Architecture\",\n",
    "    \"AI4SE\",\n",
    "    \"Program Analysis and Performance\",\n",
    "    \"Program Repair and Synthesis\",\n",
    "    \"SE4AI\",\n",
    "    \"Security and Privacy\",\n",
    "    \"Welcome to Day\",\n",
    "    \"AI for SE\",\n",
    "    \"Debugging and Troubleshooting\",\n",
    "    \"Mobile Apps\",\n",
    "    \"Code Analysis\",\n",
    "    \"Source Code Manipulation\",\n",
    "    \"Builds and Versions\",\n",
    "    \"Analysis and Types\",\n",
    "    \"Application Domains\",\n",
    "    \"Bug Prediction and Localization\",\n",
    "    \"Compilers and Languages\",\n",
    "    \"Software Vulnerabilities\",\n",
    "    \"Formal Methods and Models\",\n",
    "    \"SE for AI\",\n",
    "    \"Web, Cloud, Networking\",\n",
    "    \"Code Summarization and Recommendation\",\n",
    "    \"Software Repairs\",\n",
    "    \"Dynamic and Concolic Analysis\",\n",
    "    \"Safety-Critical and Self-Adaptive Systems\",\n",
    "    \"Code Similarities and Refactoring\",\n",
    "    \"Builds and Dependencies\",\n",
    "    \"Cloud and Distributed Systems\",\n",
    "    \"Testing AI Systems\",\n",
    "    \"Infrastructure, Build, and Logs\",\n",
    "    \"Open Source and Software Ecosystems\",\n",
    "    \"Smart Contracts, Blockchain, Energy efficiency, and green software\",\n",
    "    \"Vulnerability and Security\",\n",
    "    \"Code Generation\",\n",
    "    \"Web Development\",\n",
    "    \"Testing Tools and Techniques\",\n",
    "    \"Code Quality and Code Smells\",\n",
    "    \"Code Summarization\",\n",
    "    \"Program Verification\",\n",
    "    \"Code Change Analysis\",\n",
    "    \"Software Testing for Specialized Systems\",\n",
    "    \"Bug Detection\",\n",
    "    \"Autonomous Systems and Agents\",\n",
    "    \"Mobile Development\",\n",
    "    \"Configuration and Version Management\"\n",
    "]\n",
    "\n",
    "print(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI models for SE\n",
      "Fuzzing: applications\n",
      "Mining software repositories\n",
      "Fault localization\n",
      "Formal verification\n",
      "APIs and libraries\n",
      "Blockchain/smart contracts\n",
      "Cognitive aspects of software development\n",
      "Code smells and clones\n",
      "Fuzzing: techniques and tools\n",
      "Software architectures and design\n",
      "Software security and privacy\n",
      "AI systems engineering\n",
      "Debugging\n",
      "Defect analysis\n",
      "Developers' behaviors\n",
      "Program translation and synthesis\n",
      "Posters\n",
      "Documentation\n",
      "Software logging\n",
      "Test generation\n",
      "SE for security\n",
      "Development and evolution of AI-intensive systems\n",
      "Vulnerability analysis and assessment\n",
      "Defect detection and prediction\n",
      "Studies on gender in SE\n",
      "AI testing\n",
      "Code review\n",
      "Program repair techniques and applications\n",
      "Requirements elicitation and understanding\n",
      "Software verification\n",
      "Testing of mobile, web and games\n",
      "Recommender systems\n",
      "Program repair with and for AI\n",
      "Programming languages\n",
      "AI bias and fairness\n",
      "Requirements engineering\n",
      "Software Evolution\n",
      "Test quality and improvement\n",
      "Runtime analysis and self-adaptation\n",
      "Developers' forums\n",
      "Program comprehension\n",
      "Reverse engineering\n",
      "Software processes\n",
      "Static analysis\n",
      "Testing of database and low-level software\n",
      "Software performance\n",
      "Code generation\n",
      "Software development tools\n",
      "Fault injection and mutation\n",
      "Vulnerability detection\n",
      "Issue reporting and reproduction\n",
      "Software quality\n",
      "SE education methods and tools\n",
      "Metamorphic testing\n",
      "Pre-trained and few shot learning for SE\n",
      "Program analysis\n",
      "Vulnerability testing and patching\n",
      "Cyber-physical systems testing\n",
      "Software ecosystems\n",
      "AI & Security\n",
      "Evolution & AI\n",
      "Testing\n",
      "Analysis\n",
      "Human and Social\n",
      "Generative AI studies\n",
      "Language Models and Generated Code\n",
      "Program Repair\n",
      "Analytics\n",
      "Security\n",
      "Evolution\n",
      "Analysis and Debugging\n",
      "LLM, NN and other AI technologies\n",
      "Dependability and Formal methods\n",
      "Analytics & AI\n",
      "Program binaries - evolvability\n",
      "Testing: various bug types\n",
      "Human and Social Aspects, and Requirements\n",
      "Fuzzing\n",
      "Requirements\n",
      "Testing with and for AI\n",
      "Vulnerability Detection\n",
      "Static Detection Techniques\n",
      "Testing of AI systems\n",
      "Human Aspects\n",
      "Machine Learning\n",
      "Automated Repair\n",
      "Empirical Studies\n",
      "Program Analysis\n",
      "Code Search and Text to Code\n",
      "Log Analysis and Debugging\n",
      "Fault Diagnosis and Root Cause Analysis\n",
      "Clone and Similarity Detection\n",
      "Performance\n",
      "Formal Verification\n",
      "Models of Code and Documentation\n",
      "Software Maintenance and Comprehension\n",
      "Code Search and Completion\n",
      "Processes, Requirements, and Architecture\n",
      "AI4SE\n",
      "Program Analysis and Performance\n",
      "Program Repair and Synthesis\n",
      "SE4AI\n",
      "Security and Privacy\n",
      "Welcome to Day\n",
      "AI for SE\n",
      "Debugging and Troubleshooting\n",
      "Mobile Apps\n",
      "Code Analysis\n",
      "Source Code Manipulation\n",
      "Builds and Versions\n",
      "Analysis and Types\n",
      "Application Domains\n",
      "Bug Prediction and Localization\n",
      "Compilers and Languages\n",
      "Software Vulnerabilities\n",
      "Formal Methods and Models\n",
      "SE for AI\n",
      "Web, Cloud, Networking\n",
      "Code Summarization and Recommendation\n",
      "Software Repairs\n",
      "Dynamic and Concolic Analysis\n",
      "Safety-Critical and Self-Adaptive Systems\n",
      "Code Similarities and Refactoring\n",
      "Builds and Dependencies\n",
      "Cloud and Distributed Systems\n",
      "Testing AI Systems\n",
      "Infrastructure, Build, and Logs\n",
      "Open Source and Software Ecosystems\n",
      "Smart Contracts, Blockchain, Energy efficiency, and green software\n",
      "Vulnerability and Security\n",
      "Code Generation\n",
      "Web Development\n",
      "Testing Tools and Techniques\n",
      "Code Quality and Code Smells\n",
      "Code Summarization\n",
      "Program Verification\n",
      "Code Change Analysis\n",
      "Software Testing for Specialized Systems\n",
      "Bug Detection\n",
      "Autonomous Systems and Agents\n",
      "Mobile Development\n",
      "Configuration and Version Management\n"
     ]
    }
   ],
   "source": [
    "for session_name in merged_dict_all.keys():\n",
    "        print(f\"{session_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_lists(list1, list2):\n",
    "    # Check if each item in list1 is in list2\n",
    "    for item in list1:\n",
    "        if item not in list2:\n",
    "            print(f\"Item '{item}' from list1 is not in list2.\")\n",
    "    \n",
    "    # Check if each item in list2 is in list1\n",
    "    for item in list2:\n",
    "        if item not in list1:\n",
    "            print(f\"Item '{item}' from list2 is not in list1.\")\n",
    "\n",
    "check_lists(list1, list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark distinguished papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First create a list of distinguished papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinguished_papers = [\n",
    "    {\n",
    "        \"title\": \"Merge-Replay: Efficient IFDS-Based Taint Analysis by Consolidating Equivalent Value Flows\",\n",
    "        \"authors\": [\"Yujiang Gui\", \"Dongjie He\", \"Jingling Xue\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Domain Adaptive Code Completion via Language Models and Decoupled Domain Databases\",\n",
    "        \"authors\": [\"Ze Tang\", \"Jidong Ge\", \"Shangqing Liu\", \"Tingwei Zhu\", \"Tongtong Xu\", \"Liguo Huang\", \"Bin Luo\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"EndWatch: A Practical Method for Detecting Non-Termination in Real-World Software\",\n",
    "        \"authors\": [\"Yao Zhang\", \"Xiaofei Xie\", \"Yi Li\", \"Sen Chen\", \"Cen Zhang\", \"Xiaohong Li\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Generative Type Inference for Python\",\n",
    "        \"authors\": [\"Yun Peng\", \"Chaozheng Wang\", \"Wenxuan Wang\", \"Cuiyun Gao\", \"Michael Lyu\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Detecting Smart Home Automation Application Interferences with Domain Knowledge\",\n",
    "        \"authors\": [\"Tao Wang\", \"Wei Chen\", \"Liwei Liu\", \"Guoquan Wu\", \"Jun Wei\", \"Tao Huang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"An Empirical Study on Fine-tuning Large Language Models of Code for Automated Program Repair\",\n",
    "        \"authors\": [\"Kai Huang\", \"Xiangxin Meng\", \"Jian Zhang\", \"Yang Liu\", \"Wenjie Wang\", \"Shuhao Li\", \"Yuqing Zhang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"LeakPair: Proactive Repairing of Memory Leaks in Single Page Web Applications\",\n",
    "        \"authors\": [\"Arooba Shahoor\", \"Askar Yeltayuly Khamit\", \"Jooyong Yi\", \"Dongsun Kim\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"DeepScaler: Holistic Autoscaling for Microservices Based on Spatiotemporal GNN with Adaptive Graph Learning\",\n",
    "        \"authors\": [\"Chunyang Meng\", \"Shijie Song\", \"Haogang Tong\", \"Maolin Pan\", \"Yang Yu\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Mutation-based Fault Localization of Deep Neural Networks\",\n",
    "        \"authors\": [\"Ali Ghanbari\", \"Deepak-George Thomas\", \"Muhammad Arbab Arshad\", \"Hridesh Rajan\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"PHYFU: Fuzzing Modern Physics Simulation Engines\",\n",
    "        \"authors\": [\"Dongwei Xiao\", \"Zhibo Liu\", \"Shuai Wang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Boosting the Revealing of Detected Violations in Deep Learning Testing: A Diversity-Guided Method\",\n",
    "        \"authors\": [\"Xiaoyuan Xie\", \"Pengbo Yin\", \"Songqiang Chen\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"CARGO: AI-Guided Dependency Analysis for Migrating Monolithic Applications to Microservices Architecture\",\n",
    "        \"authors\": [\"Vikram Nitin\", \"Shubhi Asthana\", \"Baishakhi Ray\", \"Rahul Krishna\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Compiler Testing using Template Java Programs\",\n",
    "        \"authors\": [\"Zhiqiang Zang\", \"Nathan Wiatrek\", \"Milos Gligoric\", \"August Shi\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"CrystalBLEU: Precisely and Efficiently Measuring the Similarity of Code\",\n",
    "        \"authors\": [\"Aryaz Eghbali\", \"Michael Pradel\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Detecting Blocking Errors in Go Programs using Localized Abstract Interpretation\",\n",
    "        \"authors\": [\"Oskar Haarklou Veileborg\", \"Georgian-Vlad Saioc\", \"Anders Mller\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Efficient Greybox Fuzzing to Detect Memory Errors\",\n",
    "        \"authors\": [\"Jinsheng Ba\", \"Gregory J. Duck\", \"Abhik Roychoudhury\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Fuzzle: Making a Puzzle for Fuzzers\",\n",
    "        \"authors\": [\"Haeun Lee\", \"Soomin Kim\", \"Sang Kil Cha\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Has My Release Disobeyed Semantic Versioning? Static Detection Based On Semantic Differencing\",\n",
    "        \"authors\": [\"Lyuye Zhang\", \"Chengwei Liu\", \"Zhengzi Xu\", \"Sen Chen\", \"Lingling Fan\", \"Bihuan Chen\", \"Yang Liu\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"HyperAST: Enabling Efficient Analysis of Software Histories at Scale\",\n",
    "        \"authors\": [\"Quentin Le-dilavrec\", \"Djamel Eddine Khelladi\", \"Arnaud Blouin\", \"Jean-Marc Jzquel\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Learning to Construct Better Mutation Faults\",\n",
    "        \"authors\": [\"Zhao Tian\", \"Junjie Chen\", \"Qihao Zhu\", \"Junjie Yang\", \"Lingming Zhang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"QATest: A Uniform Fuzzing Framework for Question Answering Systems\",\n",
    "        \"authors\": [\"Zixi Liu\", \"Yang Feng\", \"Yining Yin\", \"Jingyu Sun\", \"Zhenyu Chen\", \"Baowen Xu\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Baldur: Whole-Proof Generation and Repair with Large Language Models\",\n",
    "        \"authors\": [\"E. First\", \"M. Rabe\", \"T. Ringer\", \"Y. Brun\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Speeding up SMT Solving via Compiler Optimization\",\n",
    "        \"authors\": [\"B. Mikek\", \"Q. Zhang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Mate! Are You Really Aware? An Explainability-Guided Testing Framework for Robustness of Malware Detectors\",\n",
    "        \"authors\": [\"R. Sun\", \"M. Xue\", \"G. Tyson\", \"T. Dong\", \"S. Li\", \"S. Wang\", \"H. Zhu\", \"S. Camtepe\", \"S. Nepal\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"A Highly Scalable, Hybrid, Cross-Platform Timing Analysis Framework Providing Accurate Differential Throughput Estimation via Instruction-Level Tracing\",\n",
    "        \"authors\": [\"M. Hsu\", \"F. Hetzelt\", \"D. Gens\", \"M. Maitland\", \"M. Franz\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"An Automated Approach to Extracting Local Variables\",\n",
    "        \"authors\": [\"X. Chi\", \"H. Liu\", \"G. Li\", \"W. Wang\", \"Y. Xia\", \"Y. Jiang\", \"Y. Zhang\", \"W. Ji\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Can Machine Learning Pipelines Be Better Configured?\",\n",
    "        \"authors\": [\"Y. Wang\", \"Y. Wang\", \"T. Zhang\", \"Y. Yu\", \"S. Cheung\", \"H. Yu\", \"Z. Zhu\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"NeuRI: Diversifying DNN Generation via Inductive Rule Inference\",\n",
    "        \"authors\": [\"J. Liu\", \"J. Peng\", \"Y. Wang\", \"L. Zhang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Benchmarking Robustness of AI-enabled Multi-sensor Fusion Systems: Challenges and Opportunities\",\n",
    "        \"authors\": [\"X. Gao\", \"Z. Wang\", \"Y. Feng\", \"L. Ma\", \"Z. Chen\", \"B. Xu\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"A Longitudinal Study of Student Contributions to OSS vs. OSS4SG with a Lightweight Intervention\",\n",
    "        \"authors\": [\"Z. Fang\", \"M. Endres\", \"T. Zimmermann\", \"D. Ford\", \"W. Weimer\", \"K. Leach\", \"Y. Huang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"LExecutor: Learning-Guided Execution\",\n",
    "        \"authors\": [\"B. Souza\", \"M. Pradel\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"TransRacer: Function Dependence-Guided Transaction Race Detection for Smart Contracts\",\n",
    "        \"authors\": [\"C. Ma\", \"W. Song\", \"J. Huang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Recommending Analogical APIs via Knowledge Graph Embedding\",\n",
    "        \"authors\": [\"M. Liu\", \"Y. Yang\", \"Y. Lou\", \"X. Peng\", \"Z. Zhou\", \"X. Du\", \"T. Yang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Component Security Ten Years Later: An Empirical Study of Cross-Layer Threats in Real-World Mobile Applications\",\n",
    "        \"authors\": [\"Keke Lian\", \"Lei Zhang\", \"Guangliang Yang\", \"Shuo Mao\", \"Xinjie Wang\", \"Yuan Zhang\", \"Min Yang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Static Application Security Testing (SAST) Tools for Smart Contracts: How Far Are We?\",\n",
    "        \"authors\": [\"Kaixuan Li\", \"Yue Xue\", \"Sen Chen\", \"Han Liu\", \"Kairan Sun\", \"Ming Hu\", \"Haijun Wang\", \"Yang Liu\", \"Yixiang Chen\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ProveNFix: Temporal Property-Guided Program Repair\",\n",
    "        \"authors\": [\"Yahui Song\", \"Xiang Gao\", \"Wenhua Li\", \"Wei-Ngan Chin\", \"Abhik Roychoudhury\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Predictive Program Slicing via Execution Knowledge-Guided Dynamic Dependence Learning\",\n",
    "        \"authors\": [\"Aashish Yadavally\", \"Yi Li\", \"Tien Nguyen\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"TraStrainer: Adaptive Sampling for Distributed Traces with System Runtime State\",\n",
    "        \"authors\": [\"Haiyu Huang\", \"Xiaoyu Zhang\", \"Pengfei Chen\", \"Zilong He\", \"Zhiming Chen\", \"Guangba Yu\", \"Hongyang Chen\", \"Chen Sun\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Fast Graph Simplification for Path-Sensitive Typestate Analysis through Tempo-Spatial Multi-Point Slicing\",\n",
    "        \"authors\": [\"Xiao Cheng\", \"Jiawei Ren\", \"Yulei Sui\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Understanding Developers Discussions and Perceptions on Non-functional Requirements: The Case of the Spring Ecosystem\",\n",
    "        \"authors\": [\"Anderson Oliveira\", \"Joo Correia\", \"Wesley K. G. Assuno\", \"Juliana Alves Pereira\", \"Rafael de Mello\", \"Daniel Coutinho\", \"Caio Barbosa\", \"Paulo Librio\", \"Alessandro Garcia\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"A Transferability Study of Interpolation-Based Hardware Model Checking to Software Verification\",\n",
    "        \"authors\": [\"Dirk Beyer\", \"Po-Chun Chien\", \"Marek Jankola\", \"Nian-Ze Lee\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Only diff Is Not Enough: Generating Commit Messages Leveraging Reasoning and Action of Large Language Model\",\n",
    "        \"authors\": [\"Jiawei Li\", \"David Farag\", \"Christian Petrov\", \"Iftekhar Ahmed\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Law Doesnt Work Like a Computer: Exploring Software Licensing Issues Faced by Legal Practitioners\",\n",
    "        \"authors\": [\"Nathan Wintersgill\", \"Trevor Stalnaker\", \"Laura A. Heymann\", \"Oscar Chaparro\", \"Denys Poshyvanyk\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Improving the Learning of Code Review Successive Tasks with Cross-Task Knowledge Distillation\",\n",
    "        \"authors\": [\"Oussama Ben Sghaier\", \"Houari Sahraoui\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Do I Belong? Modeling Sense of Virtual Community Among Linux Kernel\",\n",
    "        \"authors\": [\"Bianca Trinkenreich\", \"Klaas-Jan Stol\", \"Anita Sarma\", \"Daniel M German\", \"Marco Gerosa\", \"Igor Steinmacher\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Compatible Remediation on Vulnerabilities from Third-Party Libraries for Java Projects\",\n",
    "        \"authors\": [\"Lyuye Zhang\", \"Chengwei Liu\", \"Zhengzi Xu\", \"Sen Chen\", \"Lingling Fan\", \"Lida Zhao\", \"Jiahui Wu\", \"Yang Liu\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"A Qualitative Study on the Implementation Design Decisions of Developers\",\n",
    "        \"authors\": [\"Jenny T. Liang\", \"Maryam Arab\", \"Minhyuk Ko\", \"Amy J. Ko\", \"Thomas D. LaToza\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"STILL AROUND: Experiences and Survival Strategies of Veteran Women Software Developers\",\n",
    "        \"authors\": [\"Sterre van Breukelen\", \"Ann Barcomb\", \"Sebastian Baltes\", \"Alexander Serebrenik\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Understanding and Detecting On-the-Fly Configuration Bugs\",\n",
    "        \"authors\": [\"Teng Wang\", \"Zhouyang Jia\", \"Shanshan Li\", \"Si Zheng\", \"Yue Yu\", \"Erci Xu\", \"Shaoliang Peng\", \"Xiangke Liao\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Testing Database Engines via Query Plan Guidance\",\n",
    "        \"authors\": [\"Jinsheng Ba\", \"Manuel Rigger\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Sibyl: Improving Software Engineering Tools with SMT Selection\",\n",
    "        \"authors\": [\"Will Leeson\", \"Matthew B Dwyer\", \"Antonio Filieri\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Lejacon: A Lightweight and Efficient Approach to Java Confidential Computing on SGX\",\n",
    "        \"authors\": [\"Xinyuan Miao\", \"Ziyi Lin\", \"Shaojun Wang\", \"Lei Yu\", \"Sanhong Li\", \"Zihan Wang\", \"Pengbo Nie\", \"Yuting Chen\", \"Beijun Shen\", \"He Jiang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Efficiency Matters: Speeding Up Automated Testing with GUI Rendering Inference\",\n",
    "        \"authors\": [\"Sidong Feng\", \"Mulong Xie\", \"Chunyang Chen\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Rete: Learning Namespace Representation for Program Repair\",\n",
    "        \"authors\": [\"Nikhil Parasaram\", \"Earl Barr\", \"Sergey Mechtaev\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"EDEFuzz: A Web API Fuzzer for Excessive Data Exposures\",\n",
    "        \"authors\": [\"Lianglu Pan\", \"Shaanan Cohney\", \"Toby Murray\", \"Thuan Pham\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Modularizing while Training: a New Paradigm for Modularizing DNN Models\",\n",
    "        \"authors\": [\"Binhang Qi\", \"Hailong Sun\", \"Hongyu Zhang\", \"Ruobing Zhao\", \"Xiang Gao\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"FAIR: Flow Type-Aware Pre-Training of Compiler Intermediate Representations\",\n",
    "        \"authors\": [\"Changan Niu\", \"Chuanyi Li\", \"Vincent Ng\", \"David Lo\", \"Bin Luo\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Attention! Your Copied Data is Under Monitoring: A Systematic Study of Clipboard Usage in Android Apps\",\n",
    "        \"authors\": [\"Yongliang Chen\", \"Ruoqin Tang\", \"Chaoshun Zuo\", \"Xiaokuan Zhang\", \"Lei Xue\", \"Xiapu Luo\", \"Qingchuan Zhao\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Breaking the Flow: A Study of Interruptions During Software Engineering Activities\",\n",
    "        \"authors\": [\"Yimeng Ma\", \"Yu Huang\", \"Kevin Leach\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Code Search is All You Need? Improving Code Suggestions with Code Search\",\n",
    "        \"authors\": [\"Junkai Chen\", \"Xing Hu\", \"Zhenhao Li\", \"Cuiyun Gao\", \"Xin Xia\", \"David Lo\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Analyzing and Debugging Normative Requirements via Satisfiability Checking\",\n",
    "        \"authors\": [\"Nick Feng\", \"Lina Marsso\", \"Sinem Getir Yaman\", \"Yesugen Baatartogtokh\", \"Reem Ayad\", \"Victria Oldemburgo de Mello\", \"Beverley Townsend\", \"Isobel Standen\", \"Ioannis Stefanakos\", \"Calum Imrie\", \"Genana Nunes Rodrigues\", \"Ana Cavalcanti\", \"Radu Calinescu\", \"Marsha Chechik\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Property-based testing in practice\",\n",
    "        \"authors\": [\"Harrison Goldstein\", \"Joseph W. Cutler\", \"Daniel Dickstein\", \"Benjamin C. Pierce\", \"Andrew Head\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Causal Relationships and Programming Outcomes: A Transcranial Magnetic Stimulation Experiment\",\n",
    "        \"authors\": [\"Hammad Ahmad\", \"Madeline Endres\", \"Kaia Newman\", \"Priscila Santiesteban\", \"Emma Shedden\", \"Westley Weimer\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"GenderMag Improves Discoverability in the Field, Especially for Women\",\n",
    "        \"authors\": [\"Emerson Murphy-Hill\", \"Alberto Elizondo\", \"Ambar Murillo\", \"Marian Harbach\", \"Bogdan Vasilescu\", \"Delphine Carlson\", \"Florian Dessloch\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Hard to Read and Understand Pythonic Idioms? DeIdiom and Explain Them in Non-Idiomatic Equivalent Code\",\n",
    "        \"authors\": [\"Zejun Zhang\", \"Zhenchang Xing\", \"Dehai Zhao\", \"Qinghua Lu\", \"Xiwei (Sherry) Xu\", \"Liming Zhu\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Towards Finding Accounting Errors in Smart Contracts\",\n",
    "        \"authors\": [\"Brian Zhang\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Semantic-Enhanced Static Vulnerability Detection in Baseband Firmware\",\n",
    "        \"authors\": [\"Yiming Liu\", \"Cen Zhang\", \"Feng Li\", \"Yeting Li\", \"Jianhua Zhou\", \"Jian Wang\", \"Lanlan Zhan\", \"Yang Liu\", \"Wei Huo\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Safeguarding DeFi Smart Contracts against Oracle Deviations\",\n",
    "        \"authors\": [\"Xun Deng\", \"Sidi Mohamed Beillahi\", \"Cyrus Minwalla\", \"Han Du\", \"Andreas Veneris\", \"Fan Long\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Video-based Training for Meeting Communication Skills\",\n",
    "        \"authors\": [\"Matthias Galster\", \"Antonija Mitrovic\", \"Sanna Malinen\", \"Sreedevi Sankara Iyer\", \"Jaafaru Musa\", \"Jay Holland\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Resolving Code Review Comments with Machine Learning\",\n",
    "        \"authors\": [\"Alexander Frmmgen\", \"Jacob Austin\", \"Peter Choy\", \"Nimesh Ghelani\", \"Lera Kharatyan\", \"Gabriela Surita\", \"Elena Khrapko\", \"Pascal Lamblin\", \"Pierre-Antoine Manzagol\", \"Marcus Revaj\", \"Maxim Tabachnyk\", \"Danny Tarlow\", \"Kevin Villela\", \"Daniel Zheng\", \"Satish Chandra\", \"Petros Maniatis (Google)\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"GWP-ASan: Sampling-Based Detection of Memory-Safety Bugs in Production\",\n",
    "        \"authors\": [\"Kostya Serebryany\", \"Chris Kennelly\", \"Mitch Phillips\", \"Matt Denton\", \"Marco Elver\", \"Alexander Potapenko (Google)\", \"Matt Morehouse\", \"Vlad Tsyrklevich (unaffiliated)\", \"Christian Holler (Mozilla Corporation)\", \"Julian Lettner\", \"David Kilzer (Apple)\", \"Lander Brandt (Meta)\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"User-Centric Deployment of Automated Program Repair at Bloomberg\",\n",
    "        \"authors\": [\"David Williams\", \"James Callan (University College London)\", \"Serkan Kirbas (Bloomberg LP)\", \"Sergey Mechtaev\", \"Justyna Petke (University College London)\", \"Thomas Prideaux-Ghee (Bloomberg LP)\", \"Federica Sarro (University College London)\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"On the Costs and Benefits of Adopting Lifelong Learning for Software Analytics - Empirical Study on Brown Build and Risk Prediction\",\n",
    "        \"authors\": [\"Doriane Olewicki (Queen's University)\", \"Sarra Habchi\", \"Mathieu Nayrolles (Ubisoft Montral)\", \"Mojtaba Faramarzi (Universit de Montral)\", \"Sarath Chandar (Polytechnique Montral)\", \"Bram Adams (Queen's University)\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Beyond Self-Promotion: How Software Engineering Research Is Discussed on LinkedIn\",\n",
    "        \"authors\": [\"Marvin Wyrich\", \"Justus Bogner\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark the distinguished papers inside the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_distinguished_papers(merged_dict_all, distinguished_papers):\n",
    "    \"\"\"\n",
    "    Mark distinguished papers in the merged dictionary.\n",
    "\n",
    "    This function compares paper titles in a merged dictionary of sessions and papers\n",
    "    against a list of distinguished papers, marking each paper as 'distinguished' if\n",
    "    its title matches with any of the distinguished paper titles.\n",
    "\n",
    "    Args:\n",
    "        merged_dict_all (dict): A dictionary where each key is a session name and \n",
    "                                the value is a dictionary containing a list of papers.\n",
    "                                Each paper is represented as a dictionary with keys\n",
    "                                such as 'name' (paper title).\n",
    "        distinguished_papers (list): A list of dictionaries where each dictionary\n",
    "                                     contains a 'title' key representing the paper title.\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated merged dictionary with a new 'distinguished' key (True/False)\n",
    "              added to each paper based on the comparison.\n",
    "    \"\"\"\n",
    "    # Create a set of distinguished paper titles in lowercase for case-insensitive comparison\n",
    "    distinguished_titles = {paper['title'].lower() for paper in distinguished_papers}\n",
    "    \n",
    "    # Iterate through each session in the merged dictionary\n",
    "    for session_name, session_data in merged_dict_all.items():\n",
    "        for paper in session_data['papers']:\n",
    "            # Use 'name' instead of 'title' to access the paper title\n",
    "            paper['distinguished'] = paper['name'].lower() in distinguished_titles\n",
    "    \n",
    "    return merged_dict_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_distinguished_papers(merged_dict_all):\n",
    "    \"\"\"\n",
    "    Prints the details of distinguished papers from each session in the given dictionary.\n",
    "\n",
    "    The function iterates over all sessions in the provided dictionary, filters the distinguished papers \n",
    "    from the list of papers in each session, and prints the title, authors, and URL of each distinguished paper.\n",
    "\n",
    "    Parameters:\n",
    "    merged_dict_all (dict): A dictionary where keys are session names and values are dictionaries containing session data.\n",
    "                            Each session data dictionary must have a 'papers' key that holds a list of paper dictionaries.\n",
    "                            Each paper dictionary may contain 'name' (paper title), 'authors' (list of author names), \n",
    "                            'url' (optional URL), and a boolean 'distinguished' to indicate whether the paper is distinguished.\n",
    "    \"\"\"\n",
    "    # Iterate over each session in merged_dict_all\n",
    "    for session_name, session_data in merged_dict_all.items():\n",
    "        # Filter out distinguished papers in the current session\n",
    "        distinguished_papers_in_session = [paper for paper in session_data['papers'] if paper.get('distinguished', False)]\n",
    "        \n",
    "        if distinguished_papers_in_session:\n",
    "            print(f\"Session: {session_name}\")\n",
    "            for paper in distinguished_papers_in_session:\n",
    "                print(f\" Title: {paper['name']}\")\n",
    "                print(f\" Authors: {', '.join(paper['authors'])}\")\n",
    "                print(f\" URL: {paper.get('url', 'No URL available')}\")\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distinguished_papers(merged_dict_all):\n",
    "    total_papers = len(distinguished_papers)\n",
    "    distinguished_count = 0\n",
    "    \n",
    "    # Iterate over each session in merged_dict_all\n",
    "    for session_name, session_data in merged_dict_all.items():\n",
    "        # Iterate over each paper in the session\n",
    "        for paper in session_data['papers']:\n",
    "            # Count how many of the papers are distinguished\n",
    "            if paper.get('distinguished', False):\n",
    "                distinguished_count += 1\n",
    "    \n",
    "    # Calculate the percentage of distinguished papers\n",
    "    if total_papers > 0:\n",
    "        percentage = (distinguished_count / total_papers) * 100\n",
    "    else:\n",
    "        percentage = 0  \n",
    "    \n",
    "    return distinguished_count, percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict_all = mark_distinguished_papers(merged_dict_all, distinguished_papers)\n",
    "\n",
    "#print_distinguished_papers(merged_dict_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Distinguished Papers: 62\n",
      "Percentage of matched Distinguished Papers: 83.78%\n"
     ]
    }
   ],
   "source": [
    "distinguished_count, percentage = calculate_distinguished_papers(merged_dict_all)\n",
    "print(f\"Total Distinguished Papers: {distinguished_count}\")\n",
    "print(f\"Percentage of matched Distinguished Papers: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Distinguished Paper Title: TransRacer: Function Dependence-Guided Transaction Race Detection for Smart Contracts\n",
      "Missing Distinguished Paper Title: Component Security Ten Years Later: An Empirical Study of Cross-Layer Threats in Real-World Mobile Applications\n",
      "Missing Distinguished Paper Title: ProveNFix: Temporal Property-Guided Program Repair\n",
      "Missing Distinguished Paper Title: Understanding Developers Discussions and Perceptions on Non-functional Requirements: The Case of the Spring Ecosystem\n",
      "Missing Distinguished Paper Title: The Law Doesnt Work Like a Computer: Exploring Software Licensing Issues Faced by Legal Practitioners\n",
      "Missing Distinguished Paper Title: Do I Belong? Modeling Sense of Virtual Community Among Linux Kernel\n",
      "Missing Distinguished Paper Title: STILL AROUND: Experiences and Survival Strategies of Veteran Women Software Developers\n",
      "Missing Distinguished Paper Title: Video-based Training for Meeting Communication Skills\n",
      "Missing Distinguished Paper Title: Resolving Code Review Comments with Machine Learning\n",
      "Missing Distinguished Paper Title: GWP-ASan: Sampling-Based Detection of Memory-Safety Bugs in Production\n",
      "Missing Distinguished Paper Title: User-Centric Deployment of Automated Program Repair at Bloomberg\n",
      "Missing Distinguished Paper Title: On the Costs and Benefits of Adopting Lifelong Learning for Software Analytics - Empirical Study on Brown Build and Risk Prediction\n",
      "Missing Distinguished Paper Title: Beyond Self-Promotion: How Software Engineering Research Is Discussed on LinkedIn\n"
     ]
    }
   ],
   "source": [
    "def find_missing_distinguished_papers(distinguished_papers, merged_dict_all):\n",
    "    # Create a set of titles from the distinguished papers for easy lookup (case insensitive)\n",
    "    distinguished_titles = {paper['title'].lower() for paper in distinguished_papers}\n",
    "    \n",
    "    # Set to store titles of distinguished papers found in merged_dict_all\n",
    "    found_titles = set()\n",
    "    \n",
    "    # Iterate over each session in merged_dict_all\n",
    "    for session_name, session_data in merged_dict_all.items():\n",
    "        # Iterate over each paper in the session\n",
    "        for paper in session_data['papers']:\n",
    "            # If the paper is distinguished, add its title to found_titles\n",
    "            if paper.get('distinguished', False):\n",
    "                found_titles.add(paper['name'].lower())\n",
    "    missing_dis_papers = []\n",
    "    # Iterate through the distinguished papers and print those that were not found\n",
    "    for paper in distinguished_papers:\n",
    "        if paper['title'].lower() not in found_titles:\n",
    "            print(f\"Missing Distinguished Paper Title: {paper['title']}\")\n",
    "            missing_dis_papers.append(paper['title'])\n",
    "\n",
    "    return missing_dis_papers\n",
    "    \n",
    "missing_dis_papers = find_missing_distinguished_papers(distinguished_papers, merged_dict_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These papers that have not been matched were manually marked as distinguished in the csv file (the ones that inside the dictionary and the csv-file):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write dictionary including session and papers into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_dict_to_csv(merged_dict_all, output_filename='session and papers all conferences.csv'):\n",
    "    \"\"\"\n",
    "    Export dictionary to CSV file with nested paper details.\n",
    "    \n",
    "    Args:\n",
    "        merged_dict_all (dict): Dictionary containing paper information\n",
    "        output_filename (str): Name of output CSV file\n",
    "    \"\"\"\n",
    "    # Create the csv_file folder if it doesn't exist\n",
    "    os.makedirs('csv_files', exist_ok=True)\n",
    "    \n",
    "    # Full path to save the CSV file\n",
    "    full_path = os.path.join('csv_files', output_filename)\n",
    "    \n",
    "    with open(full_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['category', 'name', 'authors', 'url', 'distinguished']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for category, data in merged_dict_all.items():\n",
    "            for paper in data.get('papers', []):\n",
    "                writer.writerow({\n",
    "                    'category': category,\n",
    "                    'name': paper['name'],\n",
    "                    'authors': ', '.join(paper['authors']),\n",
    "                    'url': paper['url'],\n",
    "                    'distinguished': paper['distinguished']\n",
    "                })\n",
    "\n",
    "export_dict_to_csv(merged_dict_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conferences_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
